{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nv42Imh5R8du"
      },
      "source": [
        "# Мартынов В.А. ДПИ15, вариант 1\n",
        "# Домашнее задание №1: линейная регрессия и векторное дифференцирование (10 баллов).\n",
        "\n",
        "* Максимальное количество баллов за задания в ноутбуке - 11, но больше 10 оценка не ставится, поэтому для получения максимальной оценки можно сделать не все задания.\n",
        "\n",
        "* Некоторые задания будут по вариантам (всего 4 варианта). Чтобы выяснить свой вариант, посчитайте количество букв в своей фамилии, возьмете остаток от деления на 4 и прибавьте 1."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 88,
      "metadata": {
        "id": "31VuKUZ7R8dv"
      },
      "outputs": [],
      "source": [
        "import numpy as np  # библиотека для работы с матрицами и мат действиями"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zo8g-cO4R8dw"
      },
      "source": [
        "## Многомерная линейная регрессия из sklearn"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZugnUbnoR8dw"
      },
      "source": [
        "Применим многомерную регрессию из sklearn для стандартного датасета"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 89,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1gGs0WYER8dx",
        "outputId": "b8e82112-0fc2-4433-8de5-37dd2516c136"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "(10000, 100) (10000,)\n"
          ]
        }
      ],
      "source": [
        "from sklearn.datasets import make_regression  # Линейная регрессия — это метод, применяемый для прогнозирования значений на основе других значений.\n",
        "                                              # Примером линейной регрессии может быть прогнозирование зарплаты сотрудников на основе их опыта работы и уровня образования. \n",
        "                                              # В этом случае линейная регрессия поможет установить зависимость между зарплатой и такими факторами, как количество лет опыта и степень образования, что позволит предсказать, сколько может зарабатывать новый сотрудник с определенными характеристиками.\n",
        "X, y = make_regression(n_samples = 10000)     # Создадим набор данных с х = 10000 объектов и у = 100 (по умолчанию) признаков\n",
        "                                              # х - матрица признаков (опыт, образование), у - целевая переменная (зарплата)\n",
        "print(X.shape, y.shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xHY4eYuRR8dx"
      },
      "source": [
        "У нас 10000 объектов и 100 признаков. Для начала решим задачу аналитически \"из коробки\" (то есть сразу после запуска)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 90,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gJ2j0Q3qR8dx",
        "outputId": "820c88b8-54a2-40f2-c562-fdfbdecec7cd"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Среднеквадратическая ошибка:  1.3063164257480414e-25\n"
          ]
        }
      ],
      "source": [
        "from sklearn.linear_model import LinearRegression # импорт необходимых классов\n",
        "from sklearn.metrics import mean_squared_error    \n",
        "\n",
        "reg = LinearRegression().fit(X, y)                # обучаем модель с помощью класса \"LinearRegression\" методом \"fit\" на данных х и у\n",
        "print(\"Среднеквадратическая ошибка: \", mean_squared_error(y, reg.predict(X)))       # оцениваем качество модели (чем меньше ошибка, тем лучше)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tpaOvVncR8dy"
      },
      "source": [
        "Теперь попробуем обучить линейную регрессию методом градиентного спуска \"из коробки\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 91,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "miy4KW6AR8dy",
        "outputId": "5b8bb1ce-0fcc-4b74-e9aa-e82a201b8476"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Среднеквадратическая ошибка:  3.1009998892181435e-12\n",
            "Коэффициенты модели: положительные и отрицательные влияния на целевую переменную \n",
            " [ 1.43719915e-08 -7.02184689e-10  3.05536536e-08 -3.26584541e-08\n",
            "  8.04428816e+00  4.59042593e+01 -1.07900068e-08 -1.09156906e-08\n",
            "  8.10016730e+01 -7.72529857e-09  3.37404768e-08 -6.04754745e-08\n",
            " -5.05550493e-08  2.65101510e-08 -3.29004936e-08  1.26419264e-08\n",
            "  1.00917441e-08  1.87538603e-08 -3.17054094e-10 -1.63456985e-08\n",
            "  9.34498791e+01 -7.53548807e-09 -4.72637701e-08  4.72971620e-08\n",
            "  2.86907108e-08  2.74969517e-08 -1.95782334e-08 -6.14184693e-08\n",
            " -2.90782277e-08 -6.57932862e-09  1.26153561e-08 -1.52181742e-08\n",
            "  5.24592817e-08  6.70680207e-08 -4.76261103e-08 -3.05691545e-08\n",
            "  3.87405061e+00  3.16484448e+01  8.11271653e-09  3.64644592e-08\n",
            " -1.17678070e-08  4.66054705e-08 -2.98694022e-09  2.96744032e-08\n",
            " -1.71462994e-09  4.11485513e-08  2.43035212e+01  2.91791743e-08\n",
            " -2.90714756e-08  6.66131293e-08 -1.53563465e-08 -1.19073218e-08\n",
            " -3.73766019e-08  1.68101746e-08  6.04064921e-08 -1.70831427e-08\n",
            "  2.37738958e-09  1.21244573e-08 -3.75095455e-09  3.12916554e+01\n",
            " -1.47745095e-08  3.83859390e-08 -2.59819164e-08 -4.78266352e-08\n",
            " -2.60019941e-08  3.25785525e-08  1.99851615e-08  3.27964860e-08\n",
            " -3.94385702e-08 -1.18606165e-08 -8.56587772e-10  1.15351631e-08\n",
            " -3.61203499e-08  6.15974193e-09 -4.53651411e-09 -4.41065521e-08\n",
            "  6.40470259e-08 -4.95540451e-08  6.96335802e-09  7.90678602e-08\n",
            " -1.37923828e-08 -9.74502713e-08 -2.17767767e-08 -2.35840332e-08\n",
            "  2.65740180e-08  8.53799397e-09 -9.18651169e-09  1.67977467e-08\n",
            " -5.50148467e-10 -7.19956483e-08  1.45900399e-08 -3.72802995e-09\n",
            " -2.13285617e-08  6.74890951e+01 -6.17207328e-08  4.30689468e-08\n",
            "  1.09641896e-08  7.81981639e+01 -3.03771714e-08  1.12031706e-08]\n"
          ]
        }
      ],
      "source": [
        "from sklearn.linear_model import SGDRegressor\n",
        "reg = SGDRegressor(alpha=0.00000001).fit(X, y)    # обучаем модель с помощью метода градиентного спуска (alpha - скорость обучения, при низких значениях модель медленнее обновляет параметры)\n",
        "print(\"Среднеквадратическая ошибка: \", mean_squared_error(y, reg.predict(X)))      \n",
        "print(\"Коэффициенты модели: положительные и отрицательные влияния на целевую переменную\", \"\\n\", reg.coef_)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fEjCux2jR8dz"
      },
      "source": [
        "***Задание 1 (0.5 балла).*** Объясните, чем вызвано различие двух полученных значений метрики?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sQN_JVONDPMG"
      },
      "source": [
        "Причины различия среднеквадратической ошибки связаны с следующими факторами:\n",
        "\n",
        "- Шумы в данных. При использовании метода make_regression, данные могут содержать некоторый шум. Аналитический метод лучше справляется с шумами, в свою очередь градиентный спуск более чувствителен к ним\n",
        "\n",
        "- Разные методы обучения. Используя аналитический метод, модель находит точные коэффициенты, уменьшая ошибку предсказания на обучающем наборе данных. Это приводит к очень низкому значению среднеквадратической ошибки. Метод градиентного спуска является итеративным и возможна ситуация, когда он не достигает глобального минимума. Особенно заметно, если скорость обучения выбрана неудачно. В нашем случае значение среднеквадратической ошибки мало, что указывает на хорошую сходимость"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MDCcYEpcDPe6"
      },
      "source": [
        "***Задание 2 (0.5 балла).*** Подберите гиперпараметры в методе градиентного спуска так, чтобы значение MSE было близко к значению MSE, полученному при обучении LinearRegression."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_4SsUO2yDQRI"
      },
      "source": [
        "Для приближения значения MSE при градиентном спуске с MSE аналитического метода, необходимо обратить внимание на несколько параметров:\n",
        "\n",
        "- Скорость обучения\n",
        "\n",
        "Будем использовать логарифмическую последовательность значений alpha с большим диапозоном, как более эффективную.\n",
        "\n",
        "- Количество итераций\n",
        "\n",
        "Увеличим время обучения параметром mmax_iter, повысив его до 1000\n",
        "\n",
        "- Толерантность\n",
        "\n",
        "Для улучшения оптимизации был установлен параметр tol на 1e-10, чтобы привести к лучшему совпадению ошибки"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 92,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "V-skc-QVF2Dt",
        "outputId": "70bedadb-191e-4c40-8f30-8a5e55b6f6fe"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Alpha: 1e-06, MSE: 3.195038149507533e-08\n",
            "Alpha: 1e-07, MSE: 3.1905852728038416e-10\n",
            "Alpha: 1e-08, MSE: 3.2534190758641876e-12\n",
            "Alpha: 1e-09, MSE: 3.043595609776402e-14\n",
            "Alpha: 1e-10, MSE: 3.02803386680564e-16\n",
            "Alpha: 1e-11, MSE: 3.0345920683478838e-18\n",
            "Alpha: 1e-12, MSE: 2.680838578332006e-20\n",
            "Alpha: 1e-13, MSE: 1.0804888503473436e-21\n",
            "Alpha: 1e-14, MSE: 6.987998361144674e-25\n",
            "Alpha: 1e-15, MSE: 6.194130165604203e-25\n",
            "Alpha: 1e-16, MSE: 6.84971298199527e-25\n",
            "Alpha: 1e-17, MSE: 6.674559416296191e-25\n",
            "Alpha: 1e-18, MSE: 5.65084056318993e-25\n",
            "Alpha: 1e-19, MSE: 6.41292658347953e-25\n",
            "Alpha: 1e-20, MSE: 5.963619528814074e-25\n",
            "Alpha: 1e-21, MSE: 6.712752194331843e-25\n",
            "Alpha: 1e-22, MSE: 5.39325520691337e-25\n",
            "Alpha: 1e-23, MSE: 5.923214959924315e-25\n",
            "Alpha: 1e-24, MSE: 6.647606121923266e-25\n",
            "Alpha: 1e-25, MSE: 5.461337186210567e-25\n",
            "Alpha: 1e-26, MSE: 6.668315617699145e-25\n",
            "Alpha: 1e-27, MSE: 7.5331310169105685e-25\n",
            "Alpha: 1e-28, MSE: 7.082718059157283e-25\n",
            "Alpha: 1e-29, MSE: 4.755114754797769e-25\n",
            "Alpha: 1e-30, MSE: 3.44091845562458e-25\n",
            "Alpha: 1e-31, MSE: 4.178048164291559e-25\n",
            "Alpha: 1e-32, MSE: 7.976406648912669e-25\n",
            "Alpha: 1e-33, MSE: 6.505165964691531e-25\n",
            "Alpha: 1e-34, MSE: 5.585950146534817e-25\n",
            "Alpha: 1e-35, MSE: 6.361062891088878e-25\n",
            "Лучшее значение alpha: 1e-30, MSE: 3.44091845562458e-25\n"
          ]
        }
      ],
      "source": [
        "# Целевое значение MSE\n",
        "target_mse = 1.43696151737083e-25\n",
        "\n",
        "# Генерация значений alpha от 1e-6 до 1e-35 с логарифмическим шагом\n",
        "alpha_values = np.logspace(-6, -35, num=30)  # 30 значений между 1e-6 и 1e-35\n",
        "\n",
        "best_mse_diff = float('inf')  # Для отслеживания ближайшего значения к целевому MSE\n",
        "best_alpha = None\n",
        "best_mse = None\n",
        "\n",
        "for alpha in alpha_values:\n",
        "    reg = SGDRegressor(alpha=alpha, max_iter=1000, tol=1e-10)\n",
        "    reg.fit(X, y)\n",
        "    mse = mean_squared_error(y, reg.predict(X))\n",
        "\n",
        "    # Выводим текущее значение MSE\n",
        "    print(f'Alpha: {alpha}, MSE: {mse}')\n",
        "\n",
        "    # Считаем разницу между текущим MSE и целевым MSE\n",
        "    mse_diff = abs(mse - target_mse)\n",
        "\n",
        "    # Проверяем, насколько близко текущее значение MSE к целевому\n",
        "    if mse_diff < best_mse_diff:\n",
        "        best_mse_diff = mse_diff\n",
        "        best_alpha = alpha\n",
        "        best_mse = mse\n",
        "\n",
        "print(f'Лучшее значение alpha: {best_alpha}, MSE: {best_mse}')\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FiTX5X0fR8dz"
      },
      "source": [
        "## Ваша многомерная линейная регрессия"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EsCs0oZ_R8dz"
      },
      "source": [
        "***Задание 3 (5 баллов)***. Напишите собственную многомерную линейную регрессию, оптимизирующую MSE методом *градиентного спуска*. Для этого используйте шаблонный класс.\n",
        "\n",
        "Критерий остановки: либо норма разности весов на текущей и предыдущей итерациях меньше определенного значения (первый и третий варианты), либо модуль разности функционалов качества (MSE) на текущей и предыдущей итерациях меньше определенного значения (второй и четвертый варианты). Также предлагается завершать обучение в любом случае, если было произведено слишком много итераций."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 93,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Достигнуто максимальное количество итераций.\n",
            "Прогнозы: [6.94723664 6.37181915 6.42610737 7.4360019  6.43066394 6.67656682\n",
            " 7.82569763 3.50494069 6.38533018 8.01345248 8.12135324 7.03800107\n",
            " 5.80646263 7.07338698 5.69350035 6.6286577  6.17991547 5.52330695\n",
            " 6.67799403 7.58435391 5.4661947  4.61984843 6.99929293 3.94384585\n",
            " 5.08715357 5.88350439 5.35420423 4.0703354  5.30462277 4.90476107\n",
            " 3.76939927 4.85084805 4.87533612 5.00790049 5.03696361 6.79619004\n",
            " 7.34111152 4.61698767 4.0502494  4.07039086 5.29418184 5.91089845\n",
            " 5.18420711 4.41439152 7.85589982 6.30708846 6.13822125 4.31489748\n",
            " 4.24272504 4.65408225 5.41963741 8.29804068 5.80616906 6.46028812\n",
            " 7.26122441 7.27330073 5.57152606 6.19050411 7.06027719 7.50618246\n",
            " 6.43669565 7.45722256 6.26862329 4.26088214 5.46543045 5.93749546\n",
            " 4.47457728 6.49164036 6.74925595 6.01458831 6.23625905 7.43324279\n",
            " 7.40419841 6.88858787 8.40367792 6.77935608 5.79536292 6.64895165\n",
            " 6.86768141 4.08894552 6.19143944 7.88949632 8.34170592 4.4797135\n",
            " 5.12823232 4.25179626 3.48232565 5.46152915 7.40117275 4.51962832\n",
            " 5.82331336 5.09504278 7.29455766 6.42081326 5.6892924  4.6337091\n",
            " 7.15577858 6.42116012 4.47838561 4.86758183]\n"
          ]
        }
      ],
      "source": [
        "class LinearRegression:\n",
        "    def __init__(self, learning_rate=0.01, tolerance=1e-6, max_iterations=1000):\n",
        "        self.learning_rate = learning_rate\n",
        "        self.tolerance = tolerance\n",
        "        self.max_iterations = max_iterations\n",
        "        self.weights = None\n",
        "\n",
        "    def fit(self, X, y):\n",
        "        # Добавляем столбец единиц для свободного члена\n",
        "        X = np.c_[np.ones(X.shape[0]), X]\n",
        "        self.weights = np.zeros(X.shape[1])\n",
        "        \n",
        "        for iteration in range(self.max_iterations):\n",
        "            predictions = X.dot(self.weights)\n",
        "            errors = predictions - y\n",
        "            \n",
        "            # Вычисляем градиент\n",
        "            gradient = X.T.dot(errors) / len(y)\n",
        "            \n",
        "            # Обновляем веса\n",
        "            new_weights = self.weights - self.learning_rate * gradient\n",
        "            \n",
        "            # Проверяем критерий остановки\n",
        "            if np.linalg.norm(new_weights - self.weights) < self.tolerance:\n",
        "                print(f\"Схождение после {iteration} итераций.\")\n",
        "                break\n",
        "            \n",
        "            self.weights = new_weights\n",
        "        else:\n",
        "            print(\"Достигнуто максимальное количество итераций.\")\n",
        "\n",
        "    def predict(self, X):\n",
        "        # Добавляем столбец единиц для свободного члена\n",
        "        X = np.c_[np.ones(X.shape[0]), X]\n",
        "        return X.dot(self.weights)\n",
        "\n",
        "# Пример использования\n",
        "if __name__ == \"__main__\":\n",
        "    # Генерация случайных данных\n",
        "    np.random.seed(0)\n",
        "    X = np.random.rand(100, 2)  # 100 образцов, 2 признака\n",
        "    y = 3 + 2 * X[:, 0] + 4 * X[:, 1] + np.random.randn(100) * 0.1  # Линейная зависимость с шумом\n",
        "\n",
        "    # Обучение модели\n",
        "    model = LinearRegression(learning_rate=0.1, tolerance=1e-6, max_iterations=1000)\n",
        "    model.fit(X, y)\n",
        "\n",
        "    # Прогнозирование\n",
        "    predictions = model.predict(X)\n",
        "    print(\"Прогнозы:\", predictions)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yxSuQD0icBy3"
      },
      "source": [
        "***Задание 4 (2 балла)***. Добавьте l1 (первый и второй варианты) или l2 (третий и четвертый варианты) регуляризацию."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 114,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zhxOWJ06R8d0",
        "outputId": "9db8727f-8f03-4506-f30b-adb56b0007c8"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Iteration 1, MSE: 6703.6156\n",
            "Iteration 2, MSE: 6572.7026\n",
            "Iteration 3, MSE: 6444.7043\n",
            "Iteration 4, MSE: 6319.2083\n",
            "Iteration 5, MSE: 6196.1656\n",
            "Iteration 6, MSE: 6075.5281\n",
            "Iteration 7, MSE: 5957.2485\n",
            "Iteration 8, MSE: 5841.2807\n",
            "Iteration 9, MSE: 5727.5792\n",
            "Iteration 10, MSE: 5616.0997\n",
            "Iteration 11, MSE: 5506.7986\n",
            "Iteration 12, MSE: 5399.6331\n",
            "Iteration 13, MSE: 5294.5614\n",
            "Iteration 14, MSE: 5191.5424\n",
            "Iteration 15, MSE: 5090.5359\n",
            "Iteration 16, MSE: 4991.5025\n",
            "Iteration 17, MSE: 4894.4034\n",
            "Iteration 18, MSE: 4799.2008\n",
            "Iteration 19, MSE: 4705.8575\n",
            "Iteration 20, MSE: 4614.3370\n",
            "Iteration 21, MSE: 4524.6036\n",
            "Iteration 22, MSE: 4436.6224\n",
            "Iteration 23, MSE: 4350.3589\n",
            "Iteration 24, MSE: 4265.7795\n",
            "Iteration 25, MSE: 4182.8513\n",
            "Iteration 26, MSE: 4101.5418\n",
            "Iteration 27, MSE: 4021.8194\n",
            "Iteration 28, MSE: 3943.6530\n",
            "Iteration 29, MSE: 3867.0121\n",
            "Iteration 30, MSE: 3791.8668\n",
            "Iteration 31, MSE: 3718.1879\n",
            "Iteration 32, MSE: 3645.9466\n",
            "Iteration 33, MSE: 3575.1148\n",
            "Iteration 34, MSE: 3505.6648\n",
            "Iteration 35, MSE: 3437.5697\n",
            "Iteration 36, MSE: 3370.8029\n",
            "Iteration 37, MSE: 3305.3383\n",
            "Iteration 38, MSE: 3241.1506\n",
            "Iteration 39, MSE: 3178.2147\n",
            "Iteration 40, MSE: 3116.5062\n",
            "Iteration 41, MSE: 3056.0009\n",
            "Iteration 42, MSE: 2996.6753\n",
            "Iteration 43, MSE: 2938.5065\n",
            "Iteration 44, MSE: 2881.4716\n",
            "Iteration 45, MSE: 2825.5486\n",
            "Iteration 46, MSE: 2770.7157\n",
            "Iteration 47, MSE: 2716.9516\n",
            "Iteration 48, MSE: 2664.2353\n",
            "Iteration 49, MSE: 2612.5464\n",
            "Iteration 50, MSE: 2561.8647\n",
            "Iteration 51, MSE: 2512.1707\n",
            "Iteration 52, MSE: 2463.4448\n",
            "Iteration 53, MSE: 2415.6683\n",
            "Iteration 54, MSE: 2368.8226\n",
            "Iteration 55, MSE: 2322.8894\n",
            "Iteration 56, MSE: 2277.8509\n",
            "Iteration 57, MSE: 2233.6897\n",
            "Iteration 58, MSE: 2190.3886\n",
            "Iteration 59, MSE: 2147.9307\n",
            "Iteration 60, MSE: 2106.2996\n",
            "Iteration 61, MSE: 2065.4791\n",
            "Iteration 62, MSE: 2025.4534\n",
            "Iteration 63, MSE: 1986.2069\n",
            "Iteration 64, MSE: 1947.7245\n",
            "Iteration 65, MSE: 1909.9912\n",
            "Iteration 66, MSE: 1872.9923\n",
            "Iteration 67, MSE: 1836.7135\n",
            "Iteration 68, MSE: 1801.1408\n",
            "Iteration 69, MSE: 1766.2604\n",
            "Iteration 70, MSE: 1732.0586\n",
            "Iteration 71, MSE: 1698.5223\n",
            "Iteration 72, MSE: 1665.6385\n",
            "Iteration 73, MSE: 1633.3945\n",
            "Iteration 74, MSE: 1601.7776\n",
            "Iteration 75, MSE: 1570.7758\n",
            "Iteration 76, MSE: 1540.3770\n",
            "Iteration 77, MSE: 1510.5693\n",
            "Iteration 78, MSE: 1481.3414\n",
            "Iteration 79, MSE: 1452.6817\n",
            "Iteration 80, MSE: 1424.5794\n",
            "Iteration 81, MSE: 1397.0234\n",
            "Iteration 82, MSE: 1370.0031\n",
            "Iteration 83, MSE: 1343.5081\n",
            "Iteration 84, MSE: 1317.5282\n",
            "Iteration 85, MSE: 1292.0531\n",
            "Iteration 86, MSE: 1267.0732\n",
            "Iteration 87, MSE: 1242.5788\n",
            "Iteration 88, MSE: 1218.5603\n",
            "Iteration 89, MSE: 1195.0085\n",
            "Iteration 90, MSE: 1171.9143\n",
            "Iteration 91, MSE: 1149.2688\n",
            "Iteration 92, MSE: 1127.0631\n",
            "Iteration 93, MSE: 1105.2888\n",
            "Iteration 94, MSE: 1083.9375\n",
            "Iteration 95, MSE: 1063.0008\n",
            "Iteration 96, MSE: 1042.4707\n",
            "Iteration 97, MSE: 1022.3392\n",
            "Iteration 98, MSE: 1002.5987\n",
            "Iteration 99, MSE: 983.2414\n",
            "Iteration 100, MSE: 964.2599\n",
            "Iteration 101, MSE: 945.6469\n",
            "Iteration 102, MSE: 927.3952\n",
            "Iteration 103, MSE: 909.4977\n",
            "Iteration 104, MSE: 891.9476\n",
            "Iteration 105, MSE: 874.7380\n",
            "Iteration 106, MSE: 857.8624\n",
            "Iteration 107, MSE: 841.3142\n",
            "Iteration 108, MSE: 825.0871\n",
            "Iteration 109, MSE: 809.1747\n",
            "Iteration 110, MSE: 793.5711\n",
            "Iteration 111, MSE: 778.2700\n",
            "Iteration 112, MSE: 763.2658\n",
            "Iteration 113, MSE: 748.5525\n",
            "Iteration 114, MSE: 734.1246\n",
            "Iteration 115, MSE: 719.9764\n",
            "Iteration 116, MSE: 706.1025\n",
            "Iteration 117, MSE: 692.4975\n",
            "Iteration 118, MSE: 679.1563\n",
            "Iteration 119, MSE: 666.0737\n",
            "Iteration 120, MSE: 653.2447\n",
            "Iteration 121, MSE: 640.6643\n",
            "Iteration 122, MSE: 628.3276\n",
            "Iteration 123, MSE: 616.2301\n",
            "Iteration 124, MSE: 604.3669\n",
            "Iteration 125, MSE: 592.7335\n",
            "Iteration 126, MSE: 581.3255\n",
            "Iteration 127, MSE: 570.1385\n",
            "Iteration 128, MSE: 559.1681\n",
            "Iteration 129, MSE: 548.4102\n",
            "Iteration 130, MSE: 537.8606\n",
            "Iteration 131, MSE: 527.5153\n",
            "Iteration 132, MSE: 517.3703\n",
            "Iteration 133, MSE: 507.4217\n",
            "Iteration 134, MSE: 497.6657\n",
            "Iteration 135, MSE: 488.0985\n",
            "Iteration 136, MSE: 478.7165\n",
            "Iteration 137, MSE: 469.5161\n",
            "Iteration 138, MSE: 460.4936\n",
            "Iteration 139, MSE: 451.6458\n",
            "Iteration 140, MSE: 442.9692\n",
            "Iteration 141, MSE: 434.4604\n",
            "Iteration 142, MSE: 426.1162\n",
            "Iteration 143, MSE: 417.9333\n",
            "Iteration 144, MSE: 409.9088\n",
            "Iteration 145, MSE: 402.0394\n",
            "Iteration 146, MSE: 394.3222\n",
            "Iteration 147, MSE: 386.7542\n",
            "Iteration 148, MSE: 379.3325\n",
            "Iteration 149, MSE: 372.0543\n",
            "Iteration 150, MSE: 364.9168\n",
            "Iteration 151, MSE: 357.9172\n",
            "Iteration 152, MSE: 351.0529\n",
            "Iteration 153, MSE: 344.3212\n",
            "Iteration 154, MSE: 337.7196\n",
            "Iteration 155, MSE: 331.2455\n",
            "Iteration 156, MSE: 324.8965\n",
            "Iteration 157, MSE: 318.6701\n",
            "Iteration 158, MSE: 312.5640\n",
            "Iteration 159, MSE: 306.5758\n",
            "Iteration 160, MSE: 300.7033\n",
            "Iteration 161, MSE: 294.9441\n",
            "Iteration 162, MSE: 289.2962\n",
            "Iteration 163, MSE: 283.7572\n",
            "Iteration 164, MSE: 278.3252\n",
            "Iteration 165, MSE: 272.9980\n",
            "Iteration 166, MSE: 267.7736\n",
            "Iteration 167, MSE: 262.6500\n",
            "Iteration 168, MSE: 257.6253\n",
            "Iteration 169, MSE: 252.6975\n",
            "Iteration 170, MSE: 247.8648\n",
            "Iteration 171, MSE: 243.1253\n",
            "Iteration 172, MSE: 238.4772\n",
            "Iteration 173, MSE: 233.9187\n",
            "Iteration 174, MSE: 229.4481\n",
            "Iteration 175, MSE: 225.0638\n",
            "Iteration 176, MSE: 220.7639\n",
            "Iteration 177, MSE: 216.5469\n",
            "Iteration 178, MSE: 212.4112\n",
            "Iteration 179, MSE: 208.3553\n",
            "Iteration 180, MSE: 204.3774\n",
            "Iteration 181, MSE: 200.4762\n",
            "Iteration 182, MSE: 196.6502\n",
            "Iteration 183, MSE: 192.8978\n",
            "Iteration 184, MSE: 189.2178\n",
            "Iteration 185, MSE: 185.6086\n",
            "Iteration 186, MSE: 182.0689\n",
            "Iteration 187, MSE: 178.5974\n",
            "Iteration 188, MSE: 175.1927\n",
            "Iteration 189, MSE: 171.8535\n",
            "Iteration 190, MSE: 168.5786\n",
            "Iteration 191, MSE: 165.3667\n",
            "Iteration 192, MSE: 162.2167\n",
            "Iteration 193, MSE: 159.1272\n",
            "Iteration 194, MSE: 156.0972\n",
            "Iteration 195, MSE: 153.1255\n",
            "Iteration 196, MSE: 150.2109\n",
            "Iteration 197, MSE: 147.3524\n",
            "Iteration 198, MSE: 144.5488\n",
            "Iteration 199, MSE: 141.7992\n",
            "Iteration 200, MSE: 139.1024\n",
            "Iteration 201, MSE: 136.4574\n",
            "Iteration 202, MSE: 133.8633\n",
            "Iteration 203, MSE: 131.3190\n",
            "Iteration 204, MSE: 128.8237\n",
            "Iteration 205, MSE: 126.3762\n",
            "Iteration 206, MSE: 123.9758\n",
            "Iteration 207, MSE: 121.6215\n",
            "Iteration 208, MSE: 119.3124\n",
            "Iteration 209, MSE: 117.0476\n",
            "Iteration 210, MSE: 114.8263\n",
            "Iteration 211, MSE: 112.6477\n",
            "Iteration 212, MSE: 110.5109\n",
            "Iteration 213, MSE: 108.4151\n",
            "Iteration 214, MSE: 106.3595\n",
            "Iteration 215, MSE: 104.3433\n",
            "Iteration 216, MSE: 102.3659\n",
            "Iteration 217, MSE: 100.4263\n",
            "Iteration 218, MSE: 98.5240\n",
            "Iteration 219, MSE: 96.6581\n",
            "Iteration 220, MSE: 94.8280\n",
            "Iteration 221, MSE: 93.0330\n",
            "Iteration 222, MSE: 91.2724\n",
            "Iteration 223, MSE: 89.5456\n",
            "Iteration 224, MSE: 87.8518\n",
            "Iteration 225, MSE: 86.1905\n",
            "Iteration 226, MSE: 84.5610\n",
            "Iteration 227, MSE: 82.9628\n",
            "Iteration 228, MSE: 81.3951\n",
            "Iteration 229, MSE: 79.8575\n",
            "Iteration 230, MSE: 78.3493\n",
            "Iteration 231, MSE: 76.8700\n",
            "Iteration 232, MSE: 75.4190\n",
            "Iteration 233, MSE: 73.9957\n",
            "Iteration 234, MSE: 72.5997\n",
            "Iteration 235, MSE: 71.2304\n",
            "Iteration 236, MSE: 69.8873\n",
            "Iteration 237, MSE: 68.5699\n",
            "Iteration 238, MSE: 67.2777\n",
            "Iteration 239, MSE: 66.0102\n",
            "Iteration 240, MSE: 64.7669\n",
            "Iteration 241, MSE: 63.5474\n",
            "Iteration 242, MSE: 62.3511\n",
            "Iteration 243, MSE: 61.1778\n",
            "Iteration 244, MSE: 60.0268\n",
            "Iteration 245, MSE: 58.8979\n",
            "Iteration 246, MSE: 57.7905\n",
            "Iteration 247, MSE: 56.7043\n",
            "Iteration 248, MSE: 55.6387\n",
            "Iteration 249, MSE: 54.5936\n",
            "Iteration 250, MSE: 53.5683\n",
            "Iteration 251, MSE: 52.5627\n",
            "Iteration 252, MSE: 51.5762\n",
            "Iteration 253, MSE: 50.6086\n",
            "Iteration 254, MSE: 49.6594\n",
            "Iteration 255, MSE: 48.7283\n",
            "Iteration 256, MSE: 47.8149\n",
            "Iteration 257, MSE: 46.9190\n",
            "Iteration 258, MSE: 46.0401\n",
            "Iteration 259, MSE: 45.1780\n",
            "Iteration 260, MSE: 44.3323\n",
            "Iteration 261, MSE: 43.5028\n",
            "Iteration 262, MSE: 42.6890\n",
            "Iteration 263, MSE: 41.8907\n",
            "Iteration 264, MSE: 41.1076\n",
            "Iteration 265, MSE: 40.3395\n",
            "Iteration 266, MSE: 39.5859\n",
            "Iteration 267, MSE: 38.8467\n",
            "Iteration 268, MSE: 38.1215\n",
            "Iteration 269, MSE: 37.4102\n",
            "Iteration 270, MSE: 36.7123\n",
            "Iteration 271, MSE: 36.0278\n",
            "Iteration 272, MSE: 35.3562\n",
            "Iteration 273, MSE: 34.6974\n",
            "Iteration 274, MSE: 34.0511\n",
            "Iteration 275, MSE: 33.4171\n",
            "Iteration 276, MSE: 32.7952\n",
            "Iteration 277, MSE: 32.1850\n",
            "Iteration 278, MSE: 31.5865\n",
            "Iteration 279, MSE: 30.9993\n",
            "Iteration 280, MSE: 30.4232\n",
            "Iteration 281, MSE: 29.8581\n",
            "Iteration 282, MSE: 29.3037\n",
            "Iteration 283, MSE: 28.7598\n",
            "Iteration 284, MSE: 28.2263\n",
            "Iteration 285, MSE: 27.7028\n",
            "Iteration 286, MSE: 27.1893\n",
            "Iteration 287, MSE: 26.6855\n",
            "Iteration 288, MSE: 26.1912\n",
            "Iteration 289, MSE: 25.7063\n",
            "Iteration 290, MSE: 25.2306\n",
            "Iteration 291, MSE: 24.7639\n",
            "Iteration 292, MSE: 24.3060\n",
            "Iteration 293, MSE: 23.8568\n",
            "Iteration 294, MSE: 23.4161\n",
            "Iteration 295, MSE: 22.9837\n",
            "Iteration 296, MSE: 22.5595\n",
            "Iteration 297, MSE: 22.1434\n",
            "Iteration 298, MSE: 21.7351\n",
            "Iteration 299, MSE: 21.3345\n",
            "Iteration 300, MSE: 20.9414\n",
            "Iteration 301, MSE: 20.5558\n",
            "Iteration 302, MSE: 20.1775\n",
            "Iteration 303, MSE: 19.8063\n",
            "Iteration 304, MSE: 19.4422\n",
            "Iteration 305, MSE: 19.0849\n",
            "Iteration 306, MSE: 18.7343\n",
            "Iteration 307, MSE: 18.3904\n",
            "Iteration 308, MSE: 18.0529\n",
            "Iteration 309, MSE: 17.7218\n",
            "Iteration 310, MSE: 17.3970\n",
            "Iteration 311, MSE: 17.0782\n",
            "Iteration 312, MSE: 16.7655\n",
            "Iteration 313, MSE: 16.4587\n",
            "Iteration 314, MSE: 16.1576\n",
            "Iteration 315, MSE: 15.8622\n",
            "Iteration 316, MSE: 15.5723\n",
            "Iteration 317, MSE: 15.2880\n",
            "Iteration 318, MSE: 15.0089\n",
            "Iteration 319, MSE: 14.7351\n",
            "Iteration 320, MSE: 14.4665\n",
            "Iteration 321, MSE: 14.2029\n",
            "Iteration 322, MSE: 13.9442\n",
            "Iteration 323, MSE: 13.6904\n",
            "Iteration 324, MSE: 13.4414\n",
            "Iteration 325, MSE: 13.1970\n",
            "Iteration 326, MSE: 12.9573\n",
            "Iteration 327, MSE: 12.7220\n",
            "Iteration 328, MSE: 12.4911\n",
            "Iteration 329, MSE: 12.2646\n",
            "Iteration 330, MSE: 12.0423\n",
            "Iteration 331, MSE: 11.8242\n",
            "Iteration 332, MSE: 11.6102\n",
            "Iteration 333, MSE: 11.4001\n",
            "Iteration 334, MSE: 11.1940\n",
            "Iteration 335, MSE: 10.9918\n",
            "Iteration 336, MSE: 10.7933\n",
            "Iteration 337, MSE: 10.5986\n",
            "Iteration 338, MSE: 10.4075\n",
            "Iteration 339, MSE: 10.2200\n",
            "Iteration 340, MSE: 10.0359\n",
            "Iteration 341, MSE: 9.8553\n",
            "Iteration 342, MSE: 9.6781\n",
            "Iteration 343, MSE: 9.5042\n",
            "Iteration 344, MSE: 9.3335\n",
            "Iteration 345, MSE: 9.1661\n",
            "Iteration 346, MSE: 9.0017\n",
            "Iteration 347, MSE: 8.8404\n",
            "Iteration 348, MSE: 8.6821\n",
            "Iteration 349, MSE: 8.5268\n",
            "Iteration 350, MSE: 8.3743\n",
            "Iteration 351, MSE: 8.2247\n",
            "Iteration 352, MSE: 8.0779\n",
            "Iteration 353, MSE: 7.9338\n",
            "Iteration 354, MSE: 7.7923\n",
            "Iteration 355, MSE: 7.6535\n",
            "Iteration 356, MSE: 7.5173\n",
            "Iteration 357, MSE: 7.3837\n",
            "Iteration 358, MSE: 7.2525\n",
            "Iteration 359, MSE: 7.1237\n",
            "Iteration 360, MSE: 6.9973\n",
            "Iteration 361, MSE: 6.8733\n",
            "Iteration 362, MSE: 6.7515\n",
            "Iteration 363, MSE: 6.6321\n",
            "Iteration 364, MSE: 6.5148\n",
            "Iteration 365, MSE: 6.3997\n",
            "Iteration 366, MSE: 6.2867\n",
            "Iteration 367, MSE: 6.1759\n",
            "Iteration 368, MSE: 6.0670\n",
            "Iteration 369, MSE: 5.9602\n",
            "Iteration 370, MSE: 5.8554\n",
            "Iteration 371, MSE: 5.7525\n",
            "Iteration 372, MSE: 5.6515\n",
            "Iteration 373, MSE: 5.5524\n",
            "Iteration 374, MSE: 5.4551\n",
            "Iteration 375, MSE: 5.3595\n",
            "Iteration 376, MSE: 5.2658\n",
            "Iteration 377, MSE: 5.1738\n",
            "Iteration 378, MSE: 5.0834\n",
            "Iteration 379, MSE: 4.9948\n",
            "Iteration 380, MSE: 4.9077\n",
            "Iteration 381, MSE: 4.8223\n",
            "Iteration 382, MSE: 4.7384\n",
            "Iteration 383, MSE: 4.6561\n",
            "Iteration 384, MSE: 4.5753\n",
            "Iteration 385, MSE: 4.4960\n",
            "Iteration 386, MSE: 4.4181\n",
            "Iteration 387, MSE: 4.3417\n",
            "Iteration 388, MSE: 4.2666\n",
            "Iteration 389, MSE: 4.1930\n",
            "Iteration 390, MSE: 4.1206\n",
            "Iteration 391, MSE: 4.0496\n",
            "Iteration 392, MSE: 3.9800\n",
            "Iteration 393, MSE: 3.9115\n",
            "Iteration 394, MSE: 3.8444\n",
            "Iteration 395, MSE: 3.7784\n",
            "Iteration 396, MSE: 3.7137\n",
            "Iteration 397, MSE: 3.6501\n",
            "Iteration 398, MSE: 3.5878\n",
            "Iteration 399, MSE: 3.5265\n",
            "Iteration 400, MSE: 3.4664\n",
            "Iteration 401, MSE: 3.4073\n",
            "Iteration 402, MSE: 3.3493\n",
            "Iteration 403, MSE: 3.2924\n",
            "Iteration 404, MSE: 3.2366\n",
            "Iteration 405, MSE: 3.1817\n",
            "Iteration 406, MSE: 3.1278\n",
            "Iteration 407, MSE: 3.0749\n",
            "Iteration 408, MSE: 3.0230\n",
            "Iteration 409, MSE: 2.9720\n",
            "Iteration 410, MSE: 2.9220\n",
            "Iteration 411, MSE: 2.8728\n",
            "Iteration 412, MSE: 2.8246\n",
            "Iteration 413, MSE: 2.7772\n",
            "Iteration 414, MSE: 2.7306\n",
            "Iteration 415, MSE: 2.6850\n",
            "Iteration 416, MSE: 2.6401\n",
            "Iteration 417, MSE: 2.5960\n",
            "Iteration 418, MSE: 2.5528\n",
            "Iteration 419, MSE: 2.5103\n",
            "Iteration 420, MSE: 2.4686\n",
            "Iteration 421, MSE: 2.4276\n",
            "Iteration 422, MSE: 2.3874\n",
            "Iteration 423, MSE: 2.3479\n",
            "Iteration 424, MSE: 2.3091\n",
            "Iteration 425, MSE: 2.2710\n",
            "Iteration 426, MSE: 2.2336\n",
            "Iteration 427, MSE: 2.1969\n",
            "Iteration 428, MSE: 2.1608\n",
            "Iteration 429, MSE: 2.1254\n",
            "Iteration 430, MSE: 2.0906\n",
            "Iteration 431, MSE: 2.0564\n",
            "Iteration 432, MSE: 2.0229\n",
            "Iteration 433, MSE: 1.9899\n",
            "Iteration 434, MSE: 1.9575\n",
            "Iteration 435, MSE: 1.9257\n",
            "Iteration 436, MSE: 1.8945\n",
            "Iteration 437, MSE: 1.8639\n",
            "Iteration 438, MSE: 1.8337\n",
            "Iteration 439, MSE: 1.8042\n",
            "Iteration 440, MSE: 1.7751\n",
            "Iteration 441, MSE: 1.7466\n",
            "Iteration 442, MSE: 1.7185\n",
            "Iteration 443, MSE: 1.6910\n",
            "Iteration 444, MSE: 1.6639\n",
            "Iteration 445, MSE: 1.6374\n",
            "Iteration 446, MSE: 1.6113\n",
            "Iteration 447, MSE: 1.5857\n",
            "Iteration 448, MSE: 1.5605\n",
            "Iteration 449, MSE: 1.5357\n",
            "Iteration 450, MSE: 1.5115\n",
            "Iteration 451, MSE: 1.4876\n",
            "Iteration 452, MSE: 1.4641\n",
            "Iteration 453, MSE: 1.4411\n",
            "Iteration 454, MSE: 1.4185\n",
            "Iteration 455, MSE: 1.3963\n",
            "Iteration 456, MSE: 1.3744\n",
            "Iteration 457, MSE: 1.3530\n",
            "Iteration 458, MSE: 1.3319\n",
            "Iteration 459, MSE: 1.3112\n",
            "Iteration 460, MSE: 1.2909\n",
            "Iteration 461, MSE: 1.2709\n",
            "Iteration 462, MSE: 1.2512\n",
            "Iteration 463, MSE: 1.2320\n",
            "Iteration 464, MSE: 1.2130\n",
            "Iteration 465, MSE: 1.1944\n",
            "Iteration 466, MSE: 1.1761\n",
            "Iteration 467, MSE: 1.1581\n",
            "Iteration 468, MSE: 1.1405\n",
            "Iteration 469, MSE: 1.1231\n",
            "Iteration 470, MSE: 1.1060\n",
            "Iteration 471, MSE: 1.0893\n",
            "Iteration 472, MSE: 1.0728\n",
            "Iteration 473, MSE: 1.0566\n",
            "Iteration 474, MSE: 1.0407\n",
            "Iteration 475, MSE: 1.0251\n",
            "Iteration 476, MSE: 1.0098\n",
            "Iteration 477, MSE: 0.9947\n",
            "Iteration 478, MSE: 0.9799\n",
            "Iteration 479, MSE: 0.9653\n",
            "Iteration 480, MSE: 0.9510\n",
            "Iteration 481, MSE: 0.9369\n",
            "Iteration 482, MSE: 0.9231\n",
            "Iteration 483, MSE: 0.9095\n",
            "Iteration 484, MSE: 0.8961\n",
            "Iteration 485, MSE: 0.8830\n",
            "Iteration 486, MSE: 0.8701\n",
            "Iteration 487, MSE: 0.8574\n",
            "Iteration 488, MSE: 0.8450\n",
            "Iteration 489, MSE: 0.8327\n",
            "Iteration 490, MSE: 0.8207\n",
            "Iteration 491, MSE: 0.8088\n",
            "Iteration 492, MSE: 0.7972\n",
            "Iteration 493, MSE: 0.7858\n",
            "Iteration 494, MSE: 0.7745\n",
            "Iteration 495, MSE: 0.7635\n",
            "Iteration 496, MSE: 0.7526\n",
            "Iteration 497, MSE: 0.7420\n",
            "Iteration 498, MSE: 0.7315\n",
            "Iteration 499, MSE: 0.7212\n",
            "Iteration 500, MSE: 0.7110\n",
            "Iteration 501, MSE: 0.7011\n",
            "Iteration 502, MSE: 0.6913\n",
            "Iteration 503, MSE: 0.6816\n",
            "Iteration 504, MSE: 0.6721\n",
            "Iteration 505, MSE: 0.6628\n",
            "Iteration 506, MSE: 0.6537\n",
            "Iteration 507, MSE: 0.6447\n",
            "Iteration 508, MSE: 0.6358\n",
            "Iteration 509, MSE: 0.6271\n",
            "Iteration 510, MSE: 0.6186\n",
            "Iteration 511, MSE: 0.6102\n",
            "Iteration 512, MSE: 0.6019\n",
            "Iteration 513, MSE: 0.5938\n",
            "Iteration 514, MSE: 0.5858\n",
            "Iteration 515, MSE: 0.5779\n",
            "Iteration 516, MSE: 0.5702\n",
            "Iteration 517, MSE: 0.5626\n",
            "Iteration 518, MSE: 0.5551\n",
            "Iteration 519, MSE: 0.5477\n",
            "Iteration 520, MSE: 0.5405\n",
            "Iteration 521, MSE: 0.5334\n",
            "Iteration 522, MSE: 0.5264\n",
            "Iteration 523, MSE: 0.5195\n",
            "Iteration 524, MSE: 0.5128\n",
            "Iteration 525, MSE: 0.5061\n",
            "Iteration 526, MSE: 0.4996\n",
            "Iteration 527, MSE: 0.4931\n",
            "Iteration 528, MSE: 0.4868\n",
            "Iteration 529, MSE: 0.4806\n",
            "Iteration 530, MSE: 0.4744\n",
            "Iteration 531, MSE: 0.4683\n",
            "Iteration 532, MSE: 0.4624\n",
            "Iteration 533, MSE: 0.4565\n",
            "Iteration 534, MSE: 0.4507\n",
            "Iteration 535, MSE: 0.4450\n",
            "Iteration 536, MSE: 0.4395\n",
            "Iteration 537, MSE: 0.4340\n",
            "Iteration 538, MSE: 0.4285\n",
            "Iteration 539, MSE: 0.4232\n",
            "Iteration 540, MSE: 0.4181\n",
            "Iteration 541, MSE: 0.4128\n",
            "Iteration 542, MSE: 0.4078\n",
            "Iteration 543, MSE: 0.4028\n",
            "Iteration 544, MSE: 0.3979\n",
            "Iteration 545, MSE: 0.3931\n",
            "Iteration 546, MSE: 0.3883\n",
            "Iteration 547, MSE: 0.3837\n",
            "Iteration 548, MSE: 0.3791\n",
            "Iteration 549, MSE: 0.3745\n",
            "Iteration 550, MSE: 0.3701\n",
            "Iteration 551, MSE: 0.3657\n",
            "Iteration 552, MSE: 0.3614\n",
            "Iteration 553, MSE: 0.3572\n",
            "Iteration 554, MSE: 0.3529\n",
            "Iteration 555, MSE: 0.3489\n",
            "Iteration 556, MSE: 0.3449\n",
            "Iteration 557, MSE: 0.3408\n",
            "Iteration 558, MSE: 0.3369\n",
            "Iteration 559, MSE: 0.3330\n",
            "Iteration 560, MSE: 0.3292\n",
            "Iteration 561, MSE: 0.3255\n",
            "Iteration 562, MSE: 0.3218\n",
            "Iteration 563, MSE: 0.3182\n",
            "Iteration 564, MSE: 0.3146\n",
            "Iteration 565, MSE: 0.3111\n",
            "Iteration 566, MSE: 0.3077\n",
            "Iteration 567, MSE: 0.3042\n",
            "Iteration 568, MSE: 0.3009\n",
            "Iteration 569, MSE: 0.2977\n",
            "Iteration 570, MSE: 0.2944\n",
            "Iteration 571, MSE: 0.2912\n",
            "Iteration 572, MSE: 0.2880\n",
            "Iteration 573, MSE: 0.2849\n",
            "Iteration 574, MSE: 0.2819\n",
            "Iteration 575, MSE: 0.2789\n",
            "Iteration 576, MSE: 0.2759\n",
            "Iteration 577, MSE: 0.2730\n",
            "Iteration 578, MSE: 0.2701\n",
            "Iteration 579, MSE: 0.2673\n",
            "Iteration 580, MSE: 0.2645\n",
            "Iteration 581, MSE: 0.2618\n",
            "Iteration 582, MSE: 0.2591\n",
            "Iteration 583, MSE: 0.2564\n",
            "Iteration 584, MSE: 0.2539\n",
            "Iteration 585, MSE: 0.2512\n",
            "Iteration 586, MSE: 0.2487\n",
            "Iteration 587, MSE: 0.2462\n",
            "Iteration 588, MSE: 0.2437\n",
            "Iteration 589, MSE: 0.2413\n",
            "Iteration 590, MSE: 0.2389\n",
            "Iteration 591, MSE: 0.2366\n",
            "Iteration 592, MSE: 0.2342\n",
            "Iteration 593, MSE: 0.2320\n",
            "Iteration 594, MSE: 0.2298\n",
            "Iteration 595, MSE: 0.2275\n",
            "Iteration 596, MSE: 0.2253\n",
            "Iteration 597, MSE: 0.2231\n",
            "Iteration 598, MSE: 0.2211\n",
            "Iteration 599, MSE: 0.2190\n",
            "Iteration 600, MSE: 0.2169\n",
            "Iteration 601, MSE: 0.2149\n",
            "Iteration 602, MSE: 0.2129\n",
            "Iteration 603, MSE: 0.2109\n",
            "Iteration 604, MSE: 0.2090\n",
            "Iteration 605, MSE: 0.2071\n",
            "Iteration 606, MSE: 0.2052\n",
            "Iteration 607, MSE: 0.2033\n",
            "Iteration 608, MSE: 0.2015\n",
            "Iteration 609, MSE: 0.1997\n",
            "Iteration 610, MSE: 0.1979\n",
            "Iteration 611, MSE: 0.1962\n",
            "Iteration 612, MSE: 0.1944\n",
            "Iteration 613, MSE: 0.1928\n",
            "Iteration 614, MSE: 0.1911\n",
            "Iteration 615, MSE: 0.1894\n",
            "Iteration 616, MSE: 0.1878\n",
            "Iteration 617, MSE: 0.1862\n",
            "Iteration 618, MSE: 0.1846\n",
            "Iteration 619, MSE: 0.1830\n",
            "Iteration 620, MSE: 0.1815\n",
            "Iteration 621, MSE: 0.1800\n",
            "Iteration 622, MSE: 0.1785\n",
            "Iteration 623, MSE: 0.1771\n",
            "Iteration 624, MSE: 0.1756\n",
            "Iteration 625, MSE: 0.1742\n",
            "Iteration 626, MSE: 0.1728\n",
            "Iteration 627, MSE: 0.1714\n",
            "Iteration 628, MSE: 0.1700\n",
            "Iteration 629, MSE: 0.1686\n",
            "Iteration 630, MSE: 0.1673\n",
            "Iteration 631, MSE: 0.1660\n",
            "Iteration 632, MSE: 0.1647\n",
            "Iteration 633, MSE: 0.1635\n",
            "Iteration 634, MSE: 0.1622\n",
            "Iteration 635, MSE: 0.1610\n",
            "Iteration 636, MSE: 0.1597\n",
            "Iteration 637, MSE: 0.1585\n",
            "Iteration 638, MSE: 0.1574\n",
            "Iteration 639, MSE: 0.1561\n",
            "Iteration 640, MSE: 0.1550\n",
            "Iteration 641, MSE: 0.1538\n",
            "Iteration 642, MSE: 0.1527\n",
            "Iteration 643, MSE: 0.1516\n",
            "Iteration 644, MSE: 0.1505\n",
            "Iteration 645, MSE: 0.1495\n",
            "Iteration 646, MSE: 0.1484\n",
            "Iteration 647, MSE: 0.1473\n",
            "Iteration 648, MSE: 0.1463\n",
            "Iteration 649, MSE: 0.1453\n",
            "Iteration 650, MSE: 0.1443\n",
            "Iteration 651, MSE: 0.1433\n",
            "Iteration 652, MSE: 0.1423\n",
            "Iteration 653, MSE: 0.1413\n",
            "Iteration 654, MSE: 0.1404\n",
            "Iteration 655, MSE: 0.1394\n",
            "Iteration 656, MSE: 0.1385\n",
            "Iteration 657, MSE: 0.1376\n",
            "Iteration 658, MSE: 0.1367\n",
            "Iteration 659, MSE: 0.1358\n",
            "Iteration 660, MSE: 0.1349\n",
            "Iteration 661, MSE: 0.1340\n",
            "Iteration 662, MSE: 0.1332\n",
            "Iteration 663, MSE: 0.1323\n",
            "Iteration 664, MSE: 0.1315\n",
            "Iteration 665, MSE: 0.1307\n",
            "Iteration 666, MSE: 0.1299\n",
            "Iteration 667, MSE: 0.1290\n",
            "Iteration 668, MSE: 0.1283\n",
            "Iteration 669, MSE: 0.1275\n",
            "Iteration 670, MSE: 0.1267\n",
            "Iteration 671, MSE: 0.1260\n",
            "Iteration 672, MSE: 0.1252\n",
            "Iteration 673, MSE: 0.1245\n",
            "Iteration 674, MSE: 0.1237\n",
            "Iteration 675, MSE: 0.1230\n",
            "Iteration 676, MSE: 0.1223\n",
            "Iteration 677, MSE: 0.1216\n",
            "Iteration 678, MSE: 0.1209\n",
            "Iteration 679, MSE: 0.1202\n",
            "Iteration 680, MSE: 0.1196\n",
            "Iteration 681, MSE: 0.1189\n",
            "Iteration 682, MSE: 0.1182\n",
            "Iteration 683, MSE: 0.1176\n",
            "Iteration 684, MSE: 0.1169\n",
            "Iteration 685, MSE: 0.1163\n",
            "Iteration 686, MSE: 0.1157\n",
            "Iteration 687, MSE: 0.1151\n",
            "Iteration 688, MSE: 0.1144\n",
            "Iteration 689, MSE: 0.1139\n",
            "Iteration 690, MSE: 0.1132\n",
            "Iteration 691, MSE: 0.1127\n",
            "Iteration 692, MSE: 0.1121\n",
            "Iteration 693, MSE: 0.1115\n",
            "Iteration 694, MSE: 0.1110\n",
            "Iteration 695, MSE: 0.1104\n",
            "Iteration 696, MSE: 0.1099\n",
            "Iteration 697, MSE: 0.1093\n",
            "Iteration 698, MSE: 0.1088\n",
            "Iteration 699, MSE: 0.1083\n",
            "Iteration 700, MSE: 0.1077\n",
            "Iteration 701, MSE: 0.1072\n",
            "Iteration 702, MSE: 0.1067\n",
            "Iteration 703, MSE: 0.1062\n",
            "Iteration 704, MSE: 0.1057\n",
            "Iteration 705, MSE: 0.1052\n",
            "Iteration 706, MSE: 0.1048\n",
            "Iteration 707, MSE: 0.1042\n",
            "Iteration 708, MSE: 0.1038\n",
            "Iteration 709, MSE: 0.1033\n",
            "Iteration 710, MSE: 0.1029\n",
            "Iteration 711, MSE: 0.1024\n",
            "Iteration 712, MSE: 0.1020\n",
            "Iteration 713, MSE: 0.1015\n",
            "Iteration 714, MSE: 0.1011\n",
            "Iteration 715, MSE: 0.1007\n",
            "Iteration 716, MSE: 0.1002\n",
            "Iteration 717, MSE: 0.0998\n",
            "Iteration 718, MSE: 0.0993\n",
            "Iteration 719, MSE: 0.0990\n",
            "Iteration 720, MSE: 0.0986\n",
            "Iteration 721, MSE: 0.0981\n",
            "Iteration 722, MSE: 0.0978\n",
            "Iteration 723, MSE: 0.0973\n",
            "Iteration 724, MSE: 0.0970\n",
            "Iteration 725, MSE: 0.0966\n",
            "Iteration 726, MSE: 0.0962\n",
            "Iteration 727, MSE: 0.0959\n",
            "Iteration 728, MSE: 0.0955\n",
            "Iteration 729, MSE: 0.0951\n",
            "Iteration 730, MSE: 0.0947\n",
            "Iteration 731, MSE: 0.0944\n",
            "Iteration 732, MSE: 0.0940\n",
            "Iteration 733, MSE: 0.0937\n",
            "Iteration 734, MSE: 0.0933\n",
            "Iteration 735, MSE: 0.0930\n",
            "Iteration 736, MSE: 0.0927\n",
            "Iteration 737, MSE: 0.0923\n",
            "Iteration 738, MSE: 0.0920\n",
            "Iteration 739, MSE: 0.0917\n",
            "Iteration 740, MSE: 0.0914\n",
            "Iteration 741, MSE: 0.0910\n",
            "Iteration 742, MSE: 0.0907\n",
            "Iteration 743, MSE: 0.0904\n",
            "Iteration 744, MSE: 0.0901\n",
            "Iteration 745, MSE: 0.0898\n",
            "Iteration 746, MSE: 0.0895\n",
            "Iteration 747, MSE: 0.0892\n",
            "Iteration 748, MSE: 0.0889\n",
            "Iteration 749, MSE: 0.0886\n",
            "Iteration 750, MSE: 0.0884\n",
            "Iteration 751, MSE: 0.0881\n",
            "Iteration 752, MSE: 0.0878\n",
            "Iteration 753, MSE: 0.0875\n",
            "Iteration 754, MSE: 0.0873\n",
            "Iteration 755, MSE: 0.0870\n",
            "Iteration 756, MSE: 0.0867\n",
            "Iteration 757, MSE: 0.0864\n",
            "Iteration 758, MSE: 0.0862\n",
            "Iteration 759, MSE: 0.0860\n",
            "Iteration 760, MSE: 0.0857\n",
            "Схождение после 759 итераций.\n",
            "Фактическое значение MSE: 0.08568221716166008\n"
          ]
        }
      ],
      "source": [
        "class LinearRegression(object):\n",
        "    def __init__(self, alpha=0.0001, l_ratio=0.1, tol=0.001, max_iter=1000):\n",
        "        '''\n",
        "        Инициализация параметров\n",
        "        alpha - скорость обучения\n",
        "        l_ratio - параметр регуляризации (чем больше значение, тем сильнее будет штраф за большие коэффициенты)\n",
        "        tol - значение для критерия останова\n",
        "        max_iter - максимальное количество итераций обучения\n",
        "        '''\n",
        "        self.alpha = alpha                  # Скорость обучения\n",
        "        self.l_ratio = l_ratio              # Параметр регуляризации\n",
        "        self.tol = tol                      # Порог для остановки\n",
        "        self.max_iter = max_iter            # Максимальное количество итераций\n",
        "        self.weights = None                 # Коэффициенты модели\n",
        "        self.mse_history = []               # История значений MSE для отладки\n",
        "\n",
        "\n",
        "\n",
        "    def fit(self, X, y):\n",
        "        '''\n",
        "        Метод для обучения линейной регрессии\n",
        "        X - матрица признаков\n",
        "        y - вектор правильных ответов\n",
        "        '''\n",
        "        # Добавляем столбец единиц для свободного члена\n",
        "        X = np.c_[np.ones(X.shape[0]), X]\n",
        "        self.weights = np.zeros(X.shape[1])\n",
        "\n",
        "        # Основной цикл обучения\n",
        "        for iteration in range(self.max_iter):\n",
        "            # Предсказания модели\n",
        "            predictions = X.dot(self.weights)\n",
        "\n",
        "            # Вычисление ошибки (разность между предсказанными и истинными значениями)\n",
        "            errors = predictions - y\n",
        "\n",
        "            # Вычисляем градиент\n",
        "            gradient = X.T.dot(errors) / len(y)\n",
        "\n",
        "            # Добавляем L1 регуляризацию к градиенту\n",
        "            l1_gradient = self.l_ratio * np.sign(self.weights)\n",
        "            gradient += l1_gradient    \n",
        "\n",
        "            #Обновляем веса\n",
        "            new_weights = self.weights - self.alpha * gradient\n",
        "\n",
        "            # Вычисляем MSE\n",
        "            mse = np.mean(errors ** 2)\n",
        "            print(f\"Iteration {iteration + 1}, MSE: {mse:.4f}\")\n",
        "            \n",
        "            # Проверяем критерий остановки\n",
        "            if np.linalg.norm(new_weights - self.weights) < self.tol:\n",
        "                print(f\"Схождение после {iteration} итераций.\")\n",
        "                break\n",
        "            \n",
        "            self.weights = new_weights\n",
        "        else:\n",
        "            print(\"Достигнуто максимальное количество итераций.\")\n",
        "\n",
        "            \n",
        "\n",
        "\n",
        "\n",
        "    def predict(self, X):\n",
        "        '''\n",
        "        Метод для предсказаний линейной регрессии\n",
        "        X - матрица признаков\n",
        "        '''\n",
        "\n",
        "        X = np.c_[np.ones(X.shape[0]), X]\n",
        "        return X.dot(self.weights)                # Возвращаем предсказанные значения\n",
        "\n",
        "\n",
        "\n",
        "# Использование класса\n",
        "# Генерация искусственных данных для обучения (пример)\n",
        "from sklearn.datasets import make_regression\n",
        "\n",
        "X, y = make_regression(n_samples=1000, n_features=5, noise=0.1)\n",
        "\n",
        "# Создание и обучение модели линейной регрессии с L1 регуляризацией\n",
        "my_reg = LinearRegression(alpha=0.01, l_ratio=0.1)\n",
        "my_reg.fit(X, y)\n",
        "\n",
        "# Проверка качества модели с помощью MSE\n",
        "mse_value = mean_squared_error(y, my_reg.predict(X))\n",
        "print(f'Фактическое значение MSE: {mse_value}')       # Выводим значение MSE"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3_mCWCj2R8d0"
      },
      "source": [
        "***Задание 5 (1 балл)***. Обучите линейную регрессию из коробки\n",
        "\n",
        "* Используем l1-регуляризацию from sklearn.linear_model import Lasso\n",
        "* Значение параметра регуляризации 0.1.\n",
        "\n",
        "Обучите вашу линейную регрессию с тем же значением параметра регуляризации и сравните результаты. Сделайте выводы."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 115,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PvBFFHuvR8d0",
        "outputId": "99f67f57-516f-4907-d24f-18b83c2cb0c6"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Iteration 1, MSE: 18993.1008\n",
            "Iteration 2, MSE: 18641.0250\n",
            "Iteration 3, MSE: 18295.9581\n",
            "Iteration 4, MSE: 17957.2922\n",
            "Iteration 5, MSE: 17624.9083\n",
            "Iteration 6, MSE: 17298.6898\n",
            "Iteration 7, MSE: 16978.5221\n",
            "Iteration 8, MSE: 16664.2927\n",
            "Iteration 9, MSE: 16355.8913\n",
            "Iteration 10, MSE: 16053.2096\n",
            "Iteration 11, MSE: 15756.1414\n",
            "Iteration 12, MSE: 15464.5822\n",
            "Iteration 13, MSE: 15178.4298\n",
            "Iteration 14, MSE: 14897.5837\n",
            "Iteration 15, MSE: 14621.9454\n",
            "Iteration 16, MSE: 14351.4180\n",
            "Iteration 17, MSE: 14085.9067\n",
            "Iteration 18, MSE: 13825.3182\n",
            "Iteration 19, MSE: 13569.5612\n",
            "Iteration 20, MSE: 13318.5458\n",
            "Iteration 21, MSE: 13072.1840\n",
            "Iteration 22, MSE: 12830.3894\n",
            "Iteration 23, MSE: 12593.0771\n",
            "Iteration 24, MSE: 12360.1639\n",
            "Iteration 25, MSE: 12131.5681\n",
            "Iteration 26, MSE: 11907.2095\n",
            "Iteration 27, MSE: 11687.0094\n",
            "Iteration 28, MSE: 11470.8906\n",
            "Iteration 29, MSE: 11258.7773\n",
            "Iteration 30, MSE: 11050.5952\n",
            "Iteration 31, MSE: 10846.2711\n",
            "Iteration 32, MSE: 10645.7336\n",
            "Iteration 33, MSE: 10448.9123\n",
            "Iteration 34, MSE: 10255.7382\n",
            "Iteration 35, MSE: 10066.1435\n",
            "Iteration 36, MSE: 9880.0619\n",
            "Iteration 37, MSE: 9697.4281\n",
            "Iteration 38, MSE: 9518.1781\n",
            "Iteration 39, MSE: 9342.2491\n",
            "Iteration 40, MSE: 9169.5795\n",
            "Iteration 41, MSE: 9000.1087\n",
            "Iteration 42, MSE: 8833.7774\n",
            "Iteration 43, MSE: 8670.5273\n",
            "Iteration 44, MSE: 8510.3011\n",
            "Iteration 45, MSE: 8353.0429\n",
            "Iteration 46, MSE: 8198.6975\n",
            "Iteration 47, MSE: 8047.2109\n",
            "Iteration 48, MSE: 7898.5299\n",
            "Iteration 49, MSE: 7752.6026\n",
            "Iteration 50, MSE: 7609.3778\n",
            "Iteration 51, MSE: 7468.8054\n",
            "Iteration 52, MSE: 7330.8362\n",
            "Iteration 53, MSE: 7195.4218\n",
            "Iteration 54, MSE: 7062.5149\n",
            "Iteration 55, MSE: 6932.0690\n",
            "Iteration 56, MSE: 6804.0384\n",
            "Iteration 57, MSE: 6678.3782\n",
            "Iteration 58, MSE: 6555.0445\n",
            "Iteration 59, MSE: 6433.9942\n",
            "Iteration 60, MSE: 6315.1849\n",
            "Iteration 61, MSE: 6198.5750\n",
            "Iteration 62, MSE: 6084.1237\n",
            "Iteration 63, MSE: 5971.7910\n",
            "Iteration 64, MSE: 5861.5376\n",
            "Iteration 65, MSE: 5753.3249\n",
            "Iteration 66, MSE: 5647.1151\n",
            "Iteration 67, MSE: 5542.8711\n",
            "Iteration 68, MSE: 5440.5563\n",
            "Iteration 69, MSE: 5340.1350\n",
            "Iteration 70, MSE: 5241.5721\n",
            "Iteration 71, MSE: 5144.8331\n",
            "Iteration 72, MSE: 5049.8842\n",
            "Iteration 73, MSE: 4956.6922\n",
            "Iteration 74, MSE: 4865.2246\n",
            "Iteration 75, MSE: 4775.4494\n",
            "Iteration 76, MSE: 4687.3351\n",
            "Iteration 77, MSE: 4600.8510\n",
            "Iteration 78, MSE: 4515.9669\n",
            "Iteration 79, MSE: 4432.6531\n",
            "Iteration 80, MSE: 4350.8805\n",
            "Iteration 81, MSE: 4270.6205\n",
            "Iteration 82, MSE: 4191.8452\n",
            "Iteration 83, MSE: 4114.5269\n",
            "Iteration 84, MSE: 4038.6387\n",
            "Iteration 85, MSE: 3964.1540\n",
            "Iteration 86, MSE: 3891.0469\n",
            "Iteration 87, MSE: 3819.2918\n",
            "Iteration 88, MSE: 3748.8637\n",
            "Iteration 89, MSE: 3679.7379\n",
            "Iteration 90, MSE: 3611.8904\n",
            "Iteration 91, MSE: 3545.2974\n",
            "Iteration 92, MSE: 3479.9358\n",
            "Iteration 93, MSE: 3415.7826\n",
            "Iteration 94, MSE: 3352.8155\n",
            "Iteration 95, MSE: 3291.0125\n",
            "Iteration 96, MSE: 3230.3521\n",
            "Iteration 97, MSE: 3170.8131\n",
            "Iteration 98, MSE: 3112.3746\n",
            "Iteration 99, MSE: 3055.0164\n",
            "Iteration 100, MSE: 2998.7184\n",
            "Iteration 101, MSE: 2943.4610\n",
            "Iteration 102, MSE: 2889.2249\n",
            "Iteration 103, MSE: 2835.9911\n",
            "Iteration 104, MSE: 2783.7412\n",
            "Iteration 105, MSE: 2732.4568\n",
            "Iteration 106, MSE: 2682.1202\n",
            "Iteration 107, MSE: 2632.7136\n",
            "Iteration 108, MSE: 2584.2201\n",
            "Iteration 109, MSE: 2536.6225\n",
            "Iteration 110, MSE: 2489.9044\n",
            "Iteration 111, MSE: 2444.0494\n",
            "Iteration 112, MSE: 2399.0415\n",
            "Iteration 113, MSE: 2354.8651\n",
            "Iteration 114, MSE: 2311.5049\n",
            "Iteration 115, MSE: 2268.9455\n",
            "Iteration 116, MSE: 2227.1723\n",
            "Iteration 117, MSE: 2186.1707\n",
            "Iteration 118, MSE: 2145.9264\n",
            "Iteration 119, MSE: 2106.4254\n",
            "Iteration 120, MSE: 2067.6539\n",
            "Iteration 121, MSE: 2029.5984\n",
            "Iteration 122, MSE: 1992.2456\n",
            "Iteration 123, MSE: 1955.5826\n",
            "Iteration 124, MSE: 1919.5966\n",
            "Iteration 125, MSE: 1884.2751\n",
            "Iteration 126, MSE: 1849.6057\n",
            "Iteration 127, MSE: 1815.5764\n",
            "Iteration 128, MSE: 1782.1753\n",
            "Iteration 129, MSE: 1749.3909\n",
            "Iteration 130, MSE: 1717.2117\n",
            "Iteration 131, MSE: 1685.6264\n",
            "Iteration 132, MSE: 1654.6242\n",
            "Iteration 133, MSE: 1624.1942\n",
            "Iteration 134, MSE: 1594.3259\n",
            "Iteration 135, MSE: 1565.0087\n",
            "Iteration 136, MSE: 1536.2327\n",
            "Iteration 137, MSE: 1507.9877\n",
            "Iteration 138, MSE: 1480.2639\n",
            "Iteration 139, MSE: 1453.0516\n",
            "Iteration 140, MSE: 1426.3415\n",
            "Iteration 141, MSE: 1400.1242\n",
            "Iteration 142, MSE: 1374.3906\n",
            "Iteration 143, MSE: 1349.1318\n",
            "Iteration 144, MSE: 1324.3389\n",
            "Iteration 145, MSE: 1300.0034\n",
            "Iteration 146, MSE: 1276.1168\n",
            "Iteration 147, MSE: 1252.6708\n",
            "Iteration 148, MSE: 1229.6573\n",
            "Iteration 149, MSE: 1207.0682\n",
            "Iteration 150, MSE: 1184.8957\n",
            "Iteration 151, MSE: 1163.1321\n",
            "Iteration 152, MSE: 1141.7699\n",
            "Iteration 153, MSE: 1120.8016\n",
            "Iteration 154, MSE: 1100.2199\n",
            "Iteration 155, MSE: 1080.0177\n",
            "Iteration 156, MSE: 1060.1880\n",
            "Iteration 157, MSE: 1040.7238\n",
            "Iteration 158, MSE: 1021.6185\n",
            "Iteration 159, MSE: 1002.8654\n",
            "Iteration 160, MSE: 984.4580\n",
            "Iteration 161, MSE: 966.3899\n",
            "Iteration 162, MSE: 948.6548\n",
            "Iteration 163, MSE: 931.2465\n",
            "Iteration 164, MSE: 914.1591\n",
            "Iteration 165, MSE: 897.3866\n",
            "Iteration 166, MSE: 880.9232\n",
            "Iteration 167, MSE: 864.7631\n",
            "Iteration 168, MSE: 848.9008\n",
            "Iteration 169, MSE: 833.3308\n",
            "Iteration 170, MSE: 818.0476\n",
            "Iteration 171, MSE: 803.0460\n",
            "Iteration 172, MSE: 788.3208\n",
            "Iteration 173, MSE: 773.8668\n",
            "Iteration 174, MSE: 759.6790\n",
            "Iteration 175, MSE: 745.7526\n",
            "Iteration 176, MSE: 732.0826\n",
            "Iteration 177, MSE: 718.6645\n",
            "Iteration 178, MSE: 705.4934\n",
            "Iteration 179, MSE: 692.5649\n",
            "Iteration 180, MSE: 679.8744\n",
            "Iteration 181, MSE: 667.4176\n",
            "Iteration 182, MSE: 655.1901\n",
            "Iteration 183, MSE: 643.1878\n",
            "Iteration 184, MSE: 631.4064\n",
            "Iteration 185, MSE: 619.8419\n",
            "Iteration 186, MSE: 608.4903\n",
            "Iteration 187, MSE: 597.3476\n",
            "Iteration 188, MSE: 586.4100\n",
            "Iteration 189, MSE: 575.6737\n",
            "Iteration 190, MSE: 565.1350\n",
            "Iteration 191, MSE: 554.7902\n",
            "Iteration 192, MSE: 544.6358\n",
            "Iteration 193, MSE: 534.6682\n",
            "Iteration 194, MSE: 524.8840\n",
            "Iteration 195, MSE: 515.2798\n",
            "Iteration 196, MSE: 505.8523\n",
            "Iteration 197, MSE: 496.5982\n",
            "Iteration 198, MSE: 487.5143\n",
            "Iteration 199, MSE: 478.5975\n",
            "Iteration 200, MSE: 469.8447\n",
            "Iteration 201, MSE: 461.2529\n",
            "Iteration 202, MSE: 452.8191\n",
            "Iteration 203, MSE: 444.5404\n",
            "Iteration 204, MSE: 436.4139\n",
            "Iteration 205, MSE: 428.4368\n",
            "Iteration 206, MSE: 420.6063\n",
            "Iteration 207, MSE: 412.9198\n",
            "Iteration 208, MSE: 405.3747\n",
            "Iteration 209, MSE: 397.9682\n",
            "Iteration 210, MSE: 390.6978\n",
            "Iteration 211, MSE: 383.5611\n",
            "Iteration 212, MSE: 376.5555\n",
            "Iteration 213, MSE: 369.6786\n",
            "Iteration 214, MSE: 362.9282\n",
            "Iteration 215, MSE: 356.3017\n",
            "Iteration 216, MSE: 349.7970\n",
            "Iteration 217, MSE: 343.4118\n",
            "Iteration 218, MSE: 337.1439\n",
            "Iteration 219, MSE: 330.9911\n",
            "Iteration 220, MSE: 324.9514\n",
            "Iteration 221, MSE: 319.0225\n",
            "Iteration 222, MSE: 313.2026\n",
            "Iteration 223, MSE: 307.4895\n",
            "Iteration 224, MSE: 301.8814\n",
            "Iteration 225, MSE: 296.3762\n",
            "Iteration 226, MSE: 290.9721\n",
            "Iteration 227, MSE: 285.6671\n",
            "Iteration 228, MSE: 280.4596\n",
            "Iteration 229, MSE: 275.3477\n",
            "Iteration 230, MSE: 270.3296\n",
            "Iteration 231, MSE: 265.4036\n",
            "Iteration 232, MSE: 260.5680\n",
            "Iteration 233, MSE: 255.8211\n",
            "Iteration 234, MSE: 251.1613\n",
            "Iteration 235, MSE: 246.5870\n",
            "Iteration 236, MSE: 242.0966\n",
            "Iteration 237, MSE: 237.6887\n",
            "Iteration 238, MSE: 233.3615\n",
            "Iteration 239, MSE: 229.1138\n",
            "Iteration 240, MSE: 224.9439\n",
            "Iteration 241, MSE: 220.8505\n",
            "Iteration 242, MSE: 216.8322\n",
            "Iteration 243, MSE: 212.8875\n",
            "Iteration 244, MSE: 209.0152\n",
            "Iteration 245, MSE: 205.2139\n",
            "Iteration 246, MSE: 201.4822\n",
            "Iteration 247, MSE: 197.8190\n",
            "Iteration 248, MSE: 194.2229\n",
            "Iteration 249, MSE: 190.6926\n",
            "Iteration 250, MSE: 187.2271\n",
            "Iteration 251, MSE: 183.8251\n",
            "Iteration 252, MSE: 180.4854\n",
            "Iteration 253, MSE: 177.2069\n",
            "Iteration 254, MSE: 173.9885\n",
            "Iteration 255, MSE: 170.8290\n",
            "Iteration 256, MSE: 167.7274\n",
            "Iteration 257, MSE: 164.6826\n",
            "Iteration 258, MSE: 161.6935\n",
            "Iteration 259, MSE: 158.7592\n",
            "Iteration 260, MSE: 155.8786\n",
            "Iteration 261, MSE: 153.0508\n",
            "Iteration 262, MSE: 150.2747\n",
            "Iteration 263, MSE: 147.5494\n",
            "Iteration 264, MSE: 144.8740\n",
            "Iteration 265, MSE: 142.2476\n",
            "Iteration 266, MSE: 139.6692\n",
            "Iteration 267, MSE: 137.1380\n",
            "Iteration 268, MSE: 134.6531\n",
            "Iteration 269, MSE: 132.2137\n",
            "Iteration 270, MSE: 129.8188\n",
            "Iteration 271, MSE: 127.4678\n",
            "Iteration 272, MSE: 125.1598\n",
            "Iteration 273, MSE: 122.8940\n",
            "Iteration 274, MSE: 120.6696\n",
            "Iteration 275, MSE: 118.4859\n",
            "Iteration 276, MSE: 116.3422\n",
            "Iteration 277, MSE: 114.2376\n",
            "Iteration 278, MSE: 112.1714\n",
            "Iteration 279, MSE: 110.1430\n",
            "Iteration 280, MSE: 108.1517\n",
            "Iteration 281, MSE: 106.1968\n",
            "Iteration 282, MSE: 104.2776\n",
            "Iteration 283, MSE: 102.3935\n",
            "Iteration 284, MSE: 100.5437\n",
            "Iteration 285, MSE: 98.7278\n",
            "Iteration 286, MSE: 96.9450\n",
            "Iteration 287, MSE: 95.1948\n",
            "Iteration 288, MSE: 93.4765\n",
            "Iteration 289, MSE: 91.7896\n",
            "Iteration 290, MSE: 90.1335\n",
            "Iteration 291, MSE: 88.5076\n",
            "Iteration 292, MSE: 86.9114\n",
            "Iteration 293, MSE: 85.3443\n",
            "Iteration 294, MSE: 83.8058\n",
            "Iteration 295, MSE: 82.2954\n",
            "Iteration 296, MSE: 80.8125\n",
            "Iteration 297, MSE: 79.3567\n",
            "Iteration 298, MSE: 77.9274\n",
            "Iteration 299, MSE: 76.5242\n",
            "Iteration 300, MSE: 75.1466\n",
            "Iteration 301, MSE: 73.7941\n",
            "Iteration 302, MSE: 72.4662\n",
            "Iteration 303, MSE: 71.1625\n",
            "Iteration 304, MSE: 69.8827\n",
            "Iteration 305, MSE: 68.6261\n",
            "Iteration 306, MSE: 67.3924\n",
            "Iteration 307, MSE: 66.1812\n",
            "Iteration 308, MSE: 64.9920\n",
            "Iteration 309, MSE: 63.8245\n",
            "Iteration 310, MSE: 62.6783\n",
            "Iteration 311, MSE: 61.5530\n",
            "Iteration 312, MSE: 60.4481\n",
            "Iteration 313, MSE: 59.3633\n",
            "Iteration 314, MSE: 58.2983\n",
            "Iteration 315, MSE: 57.2527\n",
            "Iteration 316, MSE: 56.2261\n",
            "Iteration 317, MSE: 55.2181\n",
            "Iteration 318, MSE: 54.2286\n",
            "Iteration 319, MSE: 53.2570\n",
            "Iteration 320, MSE: 52.3030\n",
            "Iteration 321, MSE: 51.3665\n",
            "Iteration 322, MSE: 50.4469\n",
            "Iteration 323, MSE: 49.5441\n",
            "Iteration 324, MSE: 48.6576\n",
            "Iteration 325, MSE: 47.7873\n",
            "Iteration 326, MSE: 46.9328\n",
            "Iteration 327, MSE: 46.0938\n",
            "Iteration 328, MSE: 45.2701\n",
            "Iteration 329, MSE: 44.4613\n",
            "Iteration 330, MSE: 43.6672\n",
            "Iteration 331, MSE: 42.8875\n",
            "Iteration 332, MSE: 42.1220\n",
            "Iteration 333, MSE: 41.3704\n",
            "Iteration 334, MSE: 40.6324\n",
            "Iteration 335, MSE: 39.9078\n",
            "Iteration 336, MSE: 39.1964\n",
            "Iteration 337, MSE: 38.4978\n",
            "Iteration 338, MSE: 37.8120\n",
            "Iteration 339, MSE: 37.1385\n",
            "Iteration 340, MSE: 36.4773\n",
            "Iteration 341, MSE: 35.8281\n",
            "Iteration 342, MSE: 35.1906\n",
            "Iteration 343, MSE: 34.5647\n",
            "Iteration 344, MSE: 33.9501\n",
            "Iteration 345, MSE: 33.3466\n",
            "Iteration 346, MSE: 32.7541\n",
            "Iteration 347, MSE: 32.1724\n",
            "Iteration 348, MSE: 31.6011\n",
            "Iteration 349, MSE: 31.0402\n",
            "Iteration 350, MSE: 30.4894\n",
            "Iteration 351, MSE: 29.9487\n",
            "Iteration 352, MSE: 29.4177\n",
            "Iteration 353, MSE: 28.8963\n",
            "Iteration 354, MSE: 28.3843\n",
            "Iteration 355, MSE: 27.8816\n",
            "Iteration 356, MSE: 27.3880\n",
            "Iteration 357, MSE: 26.9033\n",
            "Iteration 358, MSE: 26.4274\n",
            "Iteration 359, MSE: 25.9600\n",
            "Iteration 360, MSE: 25.5011\n",
            "Iteration 361, MSE: 25.0505\n",
            "Iteration 362, MSE: 24.6081\n",
            "Iteration 363, MSE: 24.1736\n",
            "Iteration 364, MSE: 23.7470\n",
            "Iteration 365, MSE: 23.3280\n",
            "Iteration 366, MSE: 22.9167\n",
            "Iteration 367, MSE: 22.5127\n",
            "Iteration 368, MSE: 22.1161\n",
            "Iteration 369, MSE: 21.7266\n",
            "Iteration 370, MSE: 21.3441\n",
            "Iteration 371, MSE: 20.9685\n",
            "Iteration 372, MSE: 20.5997\n",
            "Iteration 373, MSE: 20.2375\n",
            "Iteration 374, MSE: 19.8819\n",
            "Iteration 375, MSE: 19.5327\n",
            "Iteration 376, MSE: 19.1897\n",
            "Iteration 377, MSE: 18.8529\n",
            "Iteration 378, MSE: 18.5222\n",
            "Iteration 379, MSE: 18.1975\n",
            "Iteration 380, MSE: 17.8786\n",
            "Iteration 381, MSE: 17.5654\n",
            "Iteration 382, MSE: 17.2578\n",
            "Iteration 383, MSE: 16.9558\n",
            "Iteration 384, MSE: 16.6592\n",
            "Iteration 385, MSE: 16.3680\n",
            "Iteration 386, MSE: 16.0820\n",
            "Iteration 387, MSE: 15.8011\n",
            "Iteration 388, MSE: 15.5252\n",
            "Iteration 389, MSE: 15.2544\n",
            "Iteration 390, MSE: 14.9883\n",
            "Iteration 391, MSE: 14.7271\n",
            "Iteration 392, MSE: 14.4705\n",
            "Iteration 393, MSE: 14.2186\n",
            "Iteration 394, MSE: 13.9711\n",
            "Iteration 395, MSE: 13.7281\n",
            "Iteration 396, MSE: 13.4895\n",
            "Iteration 397, MSE: 13.2551\n",
            "Iteration 398, MSE: 13.0250\n",
            "Iteration 399, MSE: 12.7989\n",
            "Iteration 400, MSE: 12.5769\n",
            "Iteration 401, MSE: 12.3589\n",
            "Iteration 402, MSE: 12.1448\n",
            "Iteration 403, MSE: 11.9345\n",
            "Iteration 404, MSE: 11.7280\n",
            "Iteration 405, MSE: 11.5251\n",
            "Iteration 406, MSE: 11.3259\n",
            "Iteration 407, MSE: 11.1303\n",
            "Iteration 408, MSE: 10.9381\n",
            "Iteration 409, MSE: 10.7494\n",
            "Iteration 410, MSE: 10.5640\n",
            "Iteration 411, MSE: 10.3820\n",
            "Iteration 412, MSE: 10.2032\n",
            "Iteration 413, MSE: 10.0276\n",
            "Iteration 414, MSE: 9.8551\n",
            "Iteration 415, MSE: 9.6858\n",
            "Iteration 416, MSE: 9.5194\n",
            "Iteration 417, MSE: 9.3560\n",
            "Iteration 418, MSE: 9.1955\n",
            "Iteration 419, MSE: 9.0378\n",
            "Iteration 420, MSE: 8.8830\n",
            "Iteration 421, MSE: 8.7309\n",
            "Iteration 422, MSE: 8.5816\n",
            "Iteration 423, MSE: 8.4349\n",
            "Iteration 424, MSE: 8.2908\n",
            "Iteration 425, MSE: 8.1492\n",
            "Iteration 426, MSE: 8.0102\n",
            "Iteration 427, MSE: 7.8737\n",
            "Iteration 428, MSE: 7.7395\n",
            "Iteration 429, MSE: 7.6078\n",
            "Iteration 430, MSE: 7.4784\n",
            "Iteration 431, MSE: 7.3513\n",
            "Iteration 432, MSE: 7.2264\n",
            "Iteration 433, MSE: 7.1038\n",
            "Iteration 434, MSE: 6.9833\n",
            "Iteration 435, MSE: 6.8650\n",
            "Iteration 436, MSE: 6.7487\n",
            "Iteration 437, MSE: 6.6346\n",
            "Iteration 438, MSE: 6.5224\n",
            "Iteration 439, MSE: 6.4122\n",
            "Iteration 440, MSE: 6.3040\n",
            "Iteration 441, MSE: 6.1977\n",
            "Iteration 442, MSE: 6.0933\n",
            "Iteration 443, MSE: 5.9907\n",
            "Iteration 444, MSE: 5.8899\n",
            "Iteration 445, MSE: 5.7909\n",
            "Iteration 446, MSE: 5.6937\n",
            "Iteration 447, MSE: 5.5982\n",
            "Iteration 448, MSE: 5.5043\n",
            "Iteration 449, MSE: 5.4121\n",
            "Iteration 450, MSE: 5.3216\n",
            "Iteration 451, MSE: 5.2326\n",
            "Iteration 452, MSE: 5.1452\n",
            "Iteration 453, MSE: 5.0593\n",
            "Iteration 454, MSE: 4.9750\n",
            "Iteration 455, MSE: 4.8921\n",
            "Iteration 456, MSE: 4.8107\n",
            "Iteration 457, MSE: 4.7307\n",
            "Iteration 458, MSE: 4.6521\n",
            "Iteration 459, MSE: 4.5750\n",
            "Iteration 460, MSE: 4.4991\n",
            "Iteration 461, MSE: 4.4246\n",
            "Iteration 462, MSE: 4.3514\n",
            "Iteration 463, MSE: 4.2795\n",
            "Iteration 464, MSE: 4.2088\n",
            "Iteration 465, MSE: 4.1394\n",
            "Iteration 466, MSE: 4.0712\n",
            "Iteration 467, MSE: 4.0042\n",
            "Iteration 468, MSE: 3.9384\n",
            "Iteration 469, MSE: 3.8737\n",
            "Iteration 470, MSE: 3.8101\n",
            "Iteration 471, MSE: 3.7477\n",
            "Iteration 472, MSE: 3.6863\n",
            "Iteration 473, MSE: 3.6260\n",
            "Iteration 474, MSE: 3.5668\n",
            "Iteration 475, MSE: 3.5086\n",
            "Iteration 476, MSE: 3.4514\n",
            "Iteration 477, MSE: 3.3952\n",
            "Iteration 478, MSE: 3.3400\n",
            "Iteration 479, MSE: 3.2858\n",
            "Iteration 480, MSE: 3.2325\n",
            "Iteration 481, MSE: 3.1801\n",
            "Iteration 482, MSE: 3.1286\n",
            "Iteration 483, MSE: 3.0780\n",
            "Iteration 484, MSE: 3.0283\n",
            "Iteration 485, MSE: 2.9795\n",
            "Iteration 486, MSE: 2.9315\n",
            "Iteration 487, MSE: 2.8844\n",
            "Iteration 488, MSE: 2.8380\n",
            "Iteration 489, MSE: 2.7925\n",
            "Iteration 490, MSE: 2.7478\n",
            "Iteration 491, MSE: 2.7038\n",
            "Iteration 492, MSE: 2.6606\n",
            "Iteration 493, MSE: 2.6181\n",
            "Iteration 494, MSE: 2.5764\n",
            "Iteration 495, MSE: 2.5354\n",
            "Iteration 496, MSE: 2.4951\n",
            "Iteration 497, MSE: 2.4555\n",
            "Iteration 498, MSE: 2.4165\n",
            "Iteration 499, MSE: 2.3783\n",
            "Iteration 500, MSE: 2.3407\n",
            "Iteration 501, MSE: 2.3037\n",
            "Iteration 502, MSE: 2.2674\n",
            "Iteration 503, MSE: 2.2317\n",
            "Iteration 504, MSE: 2.1967\n",
            "Iteration 505, MSE: 2.1622\n",
            "Iteration 506, MSE: 2.1283\n",
            "Iteration 507, MSE: 2.0950\n",
            "Iteration 508, MSE: 2.0623\n",
            "Iteration 509, MSE: 2.0301\n",
            "Iteration 510, MSE: 1.9985\n",
            "Iteration 511, MSE: 1.9674\n",
            "Iteration 512, MSE: 1.9369\n",
            "Iteration 513, MSE: 1.9069\n",
            "Iteration 514, MSE: 1.8773\n",
            "Iteration 515, MSE: 1.8483\n",
            "Iteration 516, MSE: 1.8198\n",
            "Iteration 517, MSE: 1.7918\n",
            "Iteration 518, MSE: 1.7643\n",
            "Iteration 519, MSE: 1.7370\n",
            "Iteration 520, MSE: 1.7104\n",
            "Iteration 521, MSE: 1.6843\n",
            "Iteration 522, MSE: 1.6584\n",
            "Iteration 523, MSE: 1.6331\n",
            "Iteration 524, MSE: 1.6083\n",
            "Iteration 525, MSE: 1.5837\n",
            "Iteration 526, MSE: 1.5597\n",
            "Iteration 527, MSE: 1.5361\n",
            "Iteration 528, MSE: 1.5127\n",
            "Iteration 529, MSE: 1.4899\n",
            "Iteration 530, MSE: 1.4675\n",
            "Iteration 531, MSE: 1.4453\n",
            "Iteration 532, MSE: 1.4236\n",
            "Iteration 533, MSE: 1.4023\n",
            "Iteration 534, MSE: 1.3812\n",
            "Iteration 535, MSE: 1.3606\n",
            "Iteration 536, MSE: 1.3402\n",
            "Iteration 537, MSE: 1.3203\n",
            "Iteration 538, MSE: 1.3007\n",
            "Iteration 539, MSE: 1.2814\n",
            "Iteration 540, MSE: 1.2624\n",
            "Iteration 541, MSE: 1.2438\n",
            "Iteration 542, MSE: 1.2254\n",
            "Iteration 543, MSE: 1.2074\n",
            "Iteration 544, MSE: 1.1897\n",
            "Iteration 545, MSE: 1.1722\n",
            "Iteration 546, MSE: 1.1551\n",
            "Iteration 547, MSE: 1.1383\n",
            "Iteration 548, MSE: 1.1216\n",
            "Iteration 549, MSE: 1.1054\n",
            "Iteration 550, MSE: 1.0894\n",
            "Iteration 551, MSE: 1.0735\n",
            "Iteration 552, MSE: 1.0581\n",
            "Iteration 553, MSE: 1.0427\n",
            "Iteration 554, MSE: 1.0278\n",
            "Iteration 555, MSE: 1.0131\n",
            "Iteration 556, MSE: 0.9985\n",
            "Iteration 557, MSE: 0.9843\n",
            "Iteration 558, MSE: 0.9703\n",
            "Iteration 559, MSE: 0.9564\n",
            "Iteration 560, MSE: 0.9429\n",
            "Iteration 561, MSE: 0.9296\n",
            "Iteration 562, MSE: 0.9164\n",
            "Iteration 563, MSE: 0.9035\n",
            "Iteration 564, MSE: 0.8907\n",
            "Iteration 565, MSE: 0.8783\n",
            "Iteration 566, MSE: 0.8661\n",
            "Iteration 567, MSE: 0.8539\n",
            "Iteration 568, MSE: 0.8421\n",
            "Iteration 569, MSE: 0.8304\n",
            "Iteration 570, MSE: 0.8188\n",
            "Iteration 571, MSE: 0.8076\n",
            "Iteration 572, MSE: 0.7964\n",
            "Iteration 573, MSE: 0.7855\n",
            "Iteration 574, MSE: 0.7747\n",
            "Iteration 575, MSE: 0.7641\n",
            "Iteration 576, MSE: 0.7537\n",
            "Iteration 577, MSE: 0.7435\n",
            "Iteration 578, MSE: 0.7333\n",
            "Iteration 579, MSE: 0.7234\n",
            "Iteration 580, MSE: 0.7136\n",
            "Iteration 581, MSE: 0.7040\n",
            "Iteration 582, MSE: 0.6946\n",
            "Iteration 583, MSE: 0.6853\n",
            "Iteration 584, MSE: 0.6762\n",
            "Iteration 585, MSE: 0.6672\n",
            "Iteration 586, MSE: 0.6583\n",
            "Iteration 587, MSE: 0.6496\n",
            "Iteration 588, MSE: 0.6410\n",
            "Iteration 589, MSE: 0.6326\n",
            "Iteration 590, MSE: 0.6243\n",
            "Iteration 591, MSE: 0.6161\n",
            "Iteration 592, MSE: 0.6081\n",
            "Iteration 593, MSE: 0.6002\n",
            "Iteration 594, MSE: 0.5924\n",
            "Iteration 595, MSE: 0.5847\n",
            "Iteration 596, MSE: 0.5771\n",
            "Iteration 597, MSE: 0.5698\n",
            "Iteration 598, MSE: 0.5625\n",
            "Iteration 599, MSE: 0.5553\n",
            "Iteration 600, MSE: 0.5482\n",
            "Iteration 601, MSE: 0.5412\n",
            "Iteration 602, MSE: 0.5344\n",
            "Iteration 603, MSE: 0.5277\n",
            "Iteration 604, MSE: 0.5210\n",
            "Iteration 605, MSE: 0.5145\n",
            "Iteration 606, MSE: 0.5081\n",
            "Iteration 607, MSE: 0.5017\n",
            "Iteration 608, MSE: 0.4956\n",
            "Iteration 609, MSE: 0.4894\n",
            "Iteration 610, MSE: 0.4834\n",
            "Iteration 611, MSE: 0.4775\n",
            "Iteration 612, MSE: 0.4716\n",
            "Iteration 613, MSE: 0.4659\n",
            "Iteration 614, MSE: 0.4601\n",
            "Iteration 615, MSE: 0.4546\n",
            "Iteration 616, MSE: 0.4492\n",
            "Iteration 617, MSE: 0.4437\n",
            "Iteration 618, MSE: 0.4384\n",
            "Iteration 619, MSE: 0.4331\n",
            "Iteration 620, MSE: 0.4280\n",
            "Iteration 621, MSE: 0.4230\n",
            "Iteration 622, MSE: 0.4179\n",
            "Iteration 623, MSE: 0.4130\n",
            "Iteration 624, MSE: 0.4081\n",
            "Iteration 625, MSE: 0.4034\n",
            "Iteration 626, MSE: 0.3987\n",
            "Iteration 627, MSE: 0.3941\n",
            "Iteration 628, MSE: 0.3895\n",
            "Iteration 629, MSE: 0.3850\n",
            "Iteration 630, MSE: 0.3806\n",
            "Iteration 631, MSE: 0.3763\n",
            "Iteration 632, MSE: 0.3720\n",
            "Iteration 633, MSE: 0.3678\n",
            "Iteration 634, MSE: 0.3636\n",
            "Iteration 635, MSE: 0.3595\n",
            "Iteration 636, MSE: 0.3555\n",
            "Iteration 637, MSE: 0.3515\n",
            "Iteration 638, MSE: 0.3477\n",
            "Iteration 639, MSE: 0.3438\n",
            "Iteration 640, MSE: 0.3400\n",
            "Iteration 641, MSE: 0.3363\n",
            "Iteration 642, MSE: 0.3326\n",
            "Iteration 643, MSE: 0.3290\n",
            "Iteration 644, MSE: 0.3254\n",
            "Iteration 645, MSE: 0.3219\n",
            "Iteration 646, MSE: 0.3185\n",
            "Iteration 647, MSE: 0.3150\n",
            "Iteration 648, MSE: 0.3117\n",
            "Iteration 649, MSE: 0.3084\n",
            "Iteration 650, MSE: 0.3051\n",
            "Iteration 651, MSE: 0.3019\n",
            "Iteration 652, MSE: 0.2987\n",
            "Iteration 653, MSE: 0.2957\n",
            "Iteration 654, MSE: 0.2925\n",
            "Iteration 655, MSE: 0.2896\n",
            "Iteration 656, MSE: 0.2866\n",
            "Iteration 657, MSE: 0.2836\n",
            "Iteration 658, MSE: 0.2808\n",
            "Iteration 659, MSE: 0.2779\n",
            "Iteration 660, MSE: 0.2751\n",
            "Iteration 661, MSE: 0.2724\n",
            "Iteration 662, MSE: 0.2696\n",
            "Iteration 663, MSE: 0.2669\n",
            "Iteration 664, MSE: 0.2643\n",
            "Iteration 665, MSE: 0.2617\n",
            "Iteration 666, MSE: 0.2591\n",
            "Iteration 667, MSE: 0.2566\n",
            "Iteration 668, MSE: 0.2541\n",
            "Iteration 669, MSE: 0.2516\n",
            "Iteration 670, MSE: 0.2492\n",
            "Iteration 671, MSE: 0.2468\n",
            "Iteration 672, MSE: 0.2445\n",
            "Iteration 673, MSE: 0.2422\n",
            "Iteration 674, MSE: 0.2398\n",
            "Iteration 675, MSE: 0.2376\n",
            "Iteration 676, MSE: 0.2354\n",
            "Iteration 677, MSE: 0.2332\n",
            "Iteration 678, MSE: 0.2311\n",
            "Iteration 679, MSE: 0.2289\n",
            "Iteration 680, MSE: 0.2268\n",
            "Iteration 681, MSE: 0.2247\n",
            "Iteration 682, MSE: 0.2227\n",
            "Iteration 683, MSE: 0.2207\n",
            "Iteration 684, MSE: 0.2187\n",
            "Iteration 685, MSE: 0.2168\n",
            "Iteration 686, MSE: 0.2148\n",
            "Iteration 687, MSE: 0.2130\n",
            "Iteration 688, MSE: 0.2111\n",
            "Iteration 689, MSE: 0.2092\n",
            "Iteration 690, MSE: 0.2074\n",
            "Iteration 691, MSE: 0.2056\n",
            "Iteration 692, MSE: 0.2039\n",
            "Iteration 693, MSE: 0.2021\n",
            "Iteration 694, MSE: 0.2004\n",
            "Iteration 695, MSE: 0.1987\n",
            "Iteration 696, MSE: 0.1970\n",
            "Iteration 697, MSE: 0.1954\n",
            "Iteration 698, MSE: 0.1937\n",
            "Iteration 699, MSE: 0.1922\n",
            "Iteration 700, MSE: 0.1906\n",
            "Iteration 701, MSE: 0.1890\n",
            "Iteration 702, MSE: 0.1875\n",
            "Iteration 703, MSE: 0.1860\n",
            "Iteration 704, MSE: 0.1845\n",
            "Iteration 705, MSE: 0.1830\n",
            "Iteration 706, MSE: 0.1816\n",
            "Iteration 707, MSE: 0.1802\n",
            "Iteration 708, MSE: 0.1787\n",
            "Iteration 709, MSE: 0.1773\n",
            "Iteration 710, MSE: 0.1759\n",
            "Iteration 711, MSE: 0.1746\n",
            "Iteration 712, MSE: 0.1733\n",
            "Iteration 713, MSE: 0.1719\n",
            "Iteration 714, MSE: 0.1706\n",
            "Iteration 715, MSE: 0.1693\n",
            "Iteration 716, MSE: 0.1681\n",
            "Iteration 717, MSE: 0.1668\n",
            "Iteration 718, MSE: 0.1656\n",
            "Iteration 719, MSE: 0.1644\n",
            "Iteration 720, MSE: 0.1632\n",
            "Iteration 721, MSE: 0.1620\n",
            "Iteration 722, MSE: 0.1608\n",
            "Iteration 723, MSE: 0.1597\n",
            "Iteration 724, MSE: 0.1586\n",
            "Iteration 725, MSE: 0.1574\n",
            "Iteration 726, MSE: 0.1563\n",
            "Iteration 727, MSE: 0.1552\n",
            "Iteration 728, MSE: 0.1541\n",
            "Iteration 729, MSE: 0.1530\n",
            "Iteration 730, MSE: 0.1520\n",
            "Iteration 731, MSE: 0.1510\n",
            "Iteration 732, MSE: 0.1500\n",
            "Iteration 733, MSE: 0.1490\n",
            "Iteration 734, MSE: 0.1479\n",
            "Iteration 735, MSE: 0.1470\n",
            "Iteration 736, MSE: 0.1460\n",
            "Iteration 737, MSE: 0.1450\n",
            "Iteration 738, MSE: 0.1441\n",
            "Iteration 739, MSE: 0.1432\n",
            "Iteration 740, MSE: 0.1423\n",
            "Iteration 741, MSE: 0.1413\n",
            "Iteration 742, MSE: 0.1404\n",
            "Iteration 743, MSE: 0.1396\n",
            "Iteration 744, MSE: 0.1387\n",
            "Iteration 745, MSE: 0.1378\n",
            "Iteration 746, MSE: 0.1370\n",
            "Iteration 747, MSE: 0.1361\n",
            "Iteration 748, MSE: 0.1353\n",
            "Iteration 749, MSE: 0.1345\n",
            "Iteration 750, MSE: 0.1337\n",
            "Iteration 751, MSE: 0.1329\n",
            "Iteration 752, MSE: 0.1321\n",
            "Iteration 753, MSE: 0.1313\n",
            "Iteration 754, MSE: 0.1306\n",
            "Iteration 755, MSE: 0.1298\n",
            "Iteration 756, MSE: 0.1290\n",
            "Iteration 757, MSE: 0.1283\n",
            "Iteration 758, MSE: 0.1276\n",
            "Iteration 759, MSE: 0.1269\n",
            "Iteration 760, MSE: 0.1261\n",
            "Iteration 761, MSE: 0.1254\n",
            "Iteration 762, MSE: 0.1247\n",
            "Iteration 763, MSE: 0.1241\n",
            "Iteration 764, MSE: 0.1234\n",
            "Iteration 765, MSE: 0.1227\n",
            "Iteration 766, MSE: 0.1221\n",
            "Iteration 767, MSE: 0.1214\n",
            "Iteration 768, MSE: 0.1208\n",
            "Iteration 769, MSE: 0.1202\n",
            "Iteration 770, MSE: 0.1195\n",
            "Iteration 771, MSE: 0.1189\n",
            "Iteration 772, MSE: 0.1182\n",
            "Iteration 773, MSE: 0.1177\n",
            "Iteration 774, MSE: 0.1170\n",
            "Iteration 775, MSE: 0.1165\n",
            "Iteration 776, MSE: 0.1159\n",
            "Iteration 777, MSE: 0.1153\n",
            "Iteration 778, MSE: 0.1148\n",
            "Iteration 779, MSE: 0.1142\n",
            "Iteration 780, MSE: 0.1136\n",
            "Iteration 781, MSE: 0.1131\n",
            "Iteration 782, MSE: 0.1125\n",
            "Iteration 783, MSE: 0.1120\n",
            "Iteration 784, MSE: 0.1115\n",
            "Iteration 785, MSE: 0.1110\n",
            "Iteration 786, MSE: 0.1104\n",
            "Iteration 787, MSE: 0.1099\n",
            "Iteration 788, MSE: 0.1094\n",
            "Iteration 789, MSE: 0.1089\n",
            "Iteration 790, MSE: 0.1085\n",
            "Iteration 791, MSE: 0.1079\n",
            "Iteration 792, MSE: 0.1075\n",
            "Iteration 793, MSE: 0.1070\n",
            "Iteration 794, MSE: 0.1065\n",
            "Iteration 795, MSE: 0.1060\n",
            "Iteration 796, MSE: 0.1056\n",
            "Iteration 797, MSE: 0.1052\n",
            "Iteration 798, MSE: 0.1047\n",
            "Iteration 799, MSE: 0.1043\n",
            "Iteration 800, MSE: 0.1038\n",
            "Iteration 801, MSE: 0.1034\n",
            "Iteration 802, MSE: 0.1030\n",
            "Iteration 803, MSE: 0.1026\n",
            "Iteration 804, MSE: 0.1022\n",
            "Iteration 805, MSE: 0.1017\n",
            "Iteration 806, MSE: 0.1013\n",
            "Iteration 807, MSE: 0.1009\n",
            "Iteration 808, MSE: 0.1005\n",
            "Iteration 809, MSE: 0.1001\n",
            "Iteration 810, MSE: 0.0997\n",
            "Iteration 811, MSE: 0.0994\n",
            "Iteration 812, MSE: 0.0990\n",
            "Iteration 813, MSE: 0.0986\n",
            "Iteration 814, MSE: 0.0982\n",
            "Iteration 815, MSE: 0.0979\n",
            "Iteration 816, MSE: 0.0975\n",
            "Iteration 817, MSE: 0.0972\n",
            "Iteration 818, MSE: 0.0968\n",
            "Iteration 819, MSE: 0.0965\n",
            "Iteration 820, MSE: 0.0961\n",
            "Iteration 821, MSE: 0.0958\n",
            "Iteration 822, MSE: 0.0954\n",
            "Iteration 823, MSE: 0.0951\n",
            "Iteration 824, MSE: 0.0948\n",
            "Iteration 825, MSE: 0.0945\n",
            "Iteration 826, MSE: 0.0941\n",
            "Iteration 827, MSE: 0.0938\n",
            "Iteration 828, MSE: 0.0935\n",
            "Iteration 829, MSE: 0.0932\n",
            "Iteration 830, MSE: 0.0929\n",
            "Iteration 831, MSE: 0.0926\n",
            "Iteration 832, MSE: 0.0923\n",
            "Iteration 833, MSE: 0.0920\n",
            "Iteration 834, MSE: 0.0917\n",
            "Iteration 835, MSE: 0.0914\n",
            "Iteration 836, MSE: 0.0911\n",
            "Iteration 837, MSE: 0.0908\n",
            "Iteration 838, MSE: 0.0905\n",
            "Iteration 839, MSE: 0.0903\n",
            "Iteration 840, MSE: 0.0900\n",
            "Iteration 841, MSE: 0.0897\n",
            "Iteration 842, MSE: 0.0894\n",
            "Iteration 843, MSE: 0.0892\n",
            "Iteration 844, MSE: 0.0889\n",
            "Iteration 845, MSE: 0.0887\n",
            "Iteration 846, MSE: 0.0884\n",
            "Iteration 847, MSE: 0.0881\n",
            "Iteration 848, MSE: 0.0879\n",
            "Iteration 849, MSE: 0.0876\n",
            "Схождение после 848 итераций.\n",
            "MSE Lasso: 0.009748\n",
            "MSE Custom Linear Regression: 0.087638\n",
            "Модель Lasso показала лучшее качество предсказания.\n"
          ]
        }
      ],
      "source": [
        "from sklearn.linear_model import Lasso\n",
        "\n",
        "# Генерация искусственных данных для обучения\n",
        "X, y = make_regression(n_samples=1000, n_features=5, noise=0.1)\n",
        "\n",
        "# Обучение линейной регрессии Lasso из коробки с L1-регуляризацией\n",
        "lasso_model = Lasso(alpha=0.01)\n",
        "lasso_model.fit(X, y)\n",
        "lasso_predictions = lasso_model.predict(X)\n",
        "lasso_mse = mean_squared_error(y, lasso_predictions)\n",
        "\n",
        "# Обучение вашей реализации линейной регрессии с тем же значением параметра регуляризации\n",
        "my_reg = LinearRegression(alpha=0.01, l_ratio=0.1)  # Установим l_ratio на 0.1\n",
        "my_reg.fit(X, y)\n",
        "my_reg_predictions = my_reg.predict(X)\n",
        "my_reg_mse = mean_squared_error(y, my_reg_predictions)\n",
        "\n",
        "# Сравнение результатов\n",
        "print(f'MSE Lasso: {lasso_mse:.6f}')\n",
        "print(f'MSE Custom Linear Regression: {my_reg_mse:.6f}')\n",
        "\n",
        "# Выводы\n",
        "if lasso_mse < my_reg_mse:\n",
        "    print(\"Модель Lasso показала лучшее качество предсказания.\")\n",
        "elif lasso_mse > my_reg_mse:\n",
        "    print(\"Ваша модель показала лучшее качество предсказания.\")\n",
        "else:\n",
        "    print(\"Обе модели показали одинаковое качество предсказания.\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f8EfFlmcP7zr"
      },
      "source": [
        "В отличие от обычной линейной регрессии, Ridge использует L2-регуляризацию, которая штрафует большие значения коэффициентов. Это помогает уменьшить их величину и тем самым улучшить обобщающую способность модели"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "umu7C3HfR8d1"
      },
      "source": [
        "***Задание 6* (1 балл).***\n",
        "Пусть $P, Q \\in \\mathbb{R}^{n\\times n}$. Найдите $\\nabla_Q tr(PQ)$"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jHpCJMsXR8d1"
      },
      "source": [
        "***Задание 7* (1 балл).***\n",
        "Пусть $x, y \\in \\mathbb{R}^{n}, M \\in \\mathbb{R}^{n\\times n}$. Найдите $\\nabla_M x^T M y$"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "s6v3r8zkR8d1"
      },
      "source": [
        "Решения заданий 6 и 7 можно написать на листочке и отправить в anytask вместе с заполненным ноутбуком."
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.9"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
